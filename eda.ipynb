{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./data/train.txt\"\n",
    "test_file = \"./data/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data file\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50220\n",
      "1    11266\n",
      "Name: label, dtype: int64\n",
      "0    25169\n",
      "1     5575\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(train_df.info())\n",
    "print(train_df.label.value_counts())\n",
    "# print(test_df.info())\n",
    "print(test_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*相似的（label=1）的数量约为不相似的（label=0）的数量的1/5，样本不均衡，不过暂时不考虑。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>花呗逾期后不能分期吗</td>\n",
       "      <td>我这个 逾期后还完了 最低还款 后 能分期吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>花呗分期清空</td>\n",
       "      <td>花呗分期查询</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>借呗逾期短信通知</td>\n",
       "      <td>如何购买花呗短信通知</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           q1                      q2  label\n",
       "0    如何得知关闭借呗                 想永久关闭借呗      0\n",
       "1      花呗扫码付钱             二维码扫描可以用花呗吗      0\n",
       "2  花呗逾期后不能分期吗  我这个 逾期后还完了 最低还款 后 能分期吗      0\n",
       "3      花呗分期清空                  花呗分期查询      0\n",
       "4    借呗逾期短信通知              如何购买花呗短信通知      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in stopwords from web EDA\n",
    "with open(\"./data/stop_words.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    stop_words_list = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in spelling correction from web EDA\n",
    "with open(\"./data/spelling_corrections.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    spell_chk = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/2x/34c79f294593wb79lvjc34g00000gn/T/jieba.cache\n",
      "Loading model cost 0.857 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"./data/dict_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_n_seq(text):\n",
    "    for token_str,replac_str in spell_chk.items():\n",
    "        text = text.replace(token_str, replac_str)\n",
    "        \n",
    "    tokens = [t for t in jieba.cut(text.strip()) if t not in stop_words_list]\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 242 ms, total: 19.8 s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['q1_tokens'] = train_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "train_df['q2_tokens'] = train_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q1_tokens'] = test_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q2_tokens'] = test_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>label</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14180</td>\n",
       "      <td>为什么提示退款方式是花呗，但是我银行卡没收到</td>\n",
       "      <td>花呗显示我还款，可我没收到货</td>\n",
       "      <td>0</td>\n",
       "      <td>[为什么, 提示, 退款, 方式, 是, 花呗, 但是, 银行卡, 没收, 到]</td>\n",
       "      <td>[花呗, 显示, 还款, 可, 没收, 到货]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15005</td>\n",
       "      <td>借呗我都是提前还款的，为什么额度不能用了</td>\n",
       "      <td>借呗提前还款能撤回吗</td>\n",
       "      <td>0</td>\n",
       "      <td>[借呗, 都, 是, 提前, 还款, 为什么, 额度, 不能, 用]</td>\n",
       "      <td>[借呗, 提前, 还款, 能, 撤回]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10773</td>\n",
       "      <td>花呗还款后还可以分期吗</td>\n",
       "      <td>蚂蚁花呗最低还款后还能不能分期</td>\n",
       "      <td>0</td>\n",
       "      <td>[花呗, 还款, 可以, 分期]</td>\n",
       "      <td>[蚂蚁花呗, 最低还款, 能不能, 分期]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23243</td>\n",
       "      <td>分期买手机花呗额度不够怎么办</td>\n",
       "      <td>想分期买手机 但是花呗额度不够 怎么办</td>\n",
       "      <td>1</td>\n",
       "      <td>[分期, 买手机, 花呗, 额度, 不够, 怎么办]</td>\n",
       "      <td>[分期, 买手机, 但是, 花呗, 额度, 不够, 怎么办]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36495</td>\n",
       "      <td>问网商贷变成借呗</td>\n",
       "      <td>有网商贷无借呗了</td>\n",
       "      <td>0</td>\n",
       "      <td>[问网, 商贷, 变成, 借呗]</td>\n",
       "      <td>[有网, 商贷, 无, 借呗]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           q1                   q2  label  \\\n",
       "14180  为什么提示退款方式是花呗，但是我银行卡没收到       花呗显示我还款，可我没收到货      0   \n",
       "15005    借呗我都是提前还款的，为什么额度不能用了           借呗提前还款能撤回吗      0   \n",
       "10773             花呗还款后还可以分期吗      蚂蚁花呗最低还款后还能不能分期      0   \n",
       "23243          分期买手机花呗额度不够怎么办  想分期买手机 但是花呗额度不够 怎么办      1   \n",
       "36495                问网商贷变成借呗             有网商贷无借呗了      0   \n",
       "\n",
       "                                      q1_tokens  \\\n",
       "14180  [为什么, 提示, 退款, 方式, 是, 花呗, 但是, 银行卡, 没收, 到]   \n",
       "15005        [借呗, 都, 是, 提前, 还款, 为什么, 额度, 不能, 用]   \n",
       "10773                          [花呗, 还款, 可以, 分期]   \n",
       "23243                [分期, 买手机, 花呗, 额度, 不够, 怎么办]   \n",
       "36495                          [问网, 商贷, 变成, 借呗]   \n",
       "\n",
       "                            q2_tokens  \n",
       "14180         [花呗, 显示, 还款, 可, 没收, 到货]  \n",
       "15005             [借呗, 提前, 还款, 能, 撤回]  \n",
       "10773           [蚂蚁花呗, 最低还款, 能不能, 分期]  \n",
       "23243  [分期, 买手机, 但是, 花呗, 额度, 不够, 怎么办]  \n",
       "36495                 [有网, 商贷, 无, 借呗]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    61486.000000\n",
      "mean         5.720782\n",
      "std          2.483575\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         38.000000\n",
      "Name: q1_tokens, dtype: float64\n",
      "count    61486.000000\n",
      "mean         5.724946\n",
      "std          2.482776\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         40.000000\n",
      "Name: q2_tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the tokens length distribution\n",
    "print(train_df.q1_tokens.str.len().describe())\n",
    "print(train_df.q2_tokens.str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional methods to get features like word count, common tokens and various distances, etc. Then fit to traditional Machine Learning models to see how is it.\n",
    "## metrics: F1 score and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try gensim word2vec first to get word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "texts_q1_test = [token for token in test_df['q1_tokens'].tolist()]\n",
    "texts_q2_test = [token for token in test_df['q2_tokens'].tolist()]\n",
    "\n",
    "texts_q1_train = [token for token in train_df['q1_tokens'].tolist()]\n",
    "texts_q2_train = [token for token in train_df['q2_tokens'].tolist()]\n",
    "\n",
    "texts.extend(texts_q1_test)\n",
    "texts.extend(texts_q2_test)\n",
    "texts.extend(texts_q1_train)\n",
    "texts.extend(texts_q2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.5 s, sys: 283 ms, total: 23.8 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gensim_w2v_model = word2vec.Word2Vec(sentences=texts,size=300,window=2,min_count=3,workers=2)\n",
    "norm_gensim_w2v_model = word2vec.Word2Vec(sentences=texts,size=300,window=2,min_count=3,workers=2)\n",
    "norm_gensim_w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.16388924,  0.12370202, -0.32948422,  0.31775227,  0.30674124,\n",
       "        0.48292193, -0.44773853,  0.5484049 ,  0.47294316, -0.22289571,\n",
       "        0.47108287, -0.20134819, -0.43011713, -0.12828882, -0.34325904,\n",
       "        0.00419096, -0.24503604, -0.10676538, -0.2408275 , -0.4916334 ,\n",
       "        0.45288894,  0.08521263, -0.32905066,  0.11315393, -0.40717593,\n",
       "        0.0571479 ,  0.21153755,  0.28471413, -0.32342988, -0.9595714 ,\n",
       "        0.10519151, -0.02142261, -0.23709074,  0.24291766,  0.474836  ,\n",
       "        0.12801127,  0.09043673, -0.09429657, -0.53035665, -0.3552063 ,\n",
       "        0.3035092 ,  0.03315999,  0.78071964, -0.33745334,  0.4885339 ,\n",
       "        0.4576801 ,  0.1887161 ,  0.24093445, -0.02487267,  0.17115097,\n",
       "        1.1247121 ,  0.37978643,  0.20268022, -0.10992901,  0.21299408,\n",
       "        0.22083037, -0.16118012, -0.78722584, -0.6230208 ,  0.06565747,\n",
       "       -0.00892398,  0.10780478,  0.91244274,  0.12706824, -0.2808622 ,\n",
       "       -0.09230115,  0.35025463, -0.2606098 ,  0.1135275 , -0.39829296,\n",
       "        0.17879438,  0.46126813,  0.3839915 , -0.03235906, -0.08629654,\n",
       "        0.14237526, -0.18973657,  0.14191683,  0.05568745, -0.05730615,\n",
       "       -0.20577885, -0.873857  ,  0.22337073, -0.33568865,  0.5609437 ,\n",
       "       -0.19409597,  0.7158242 , -0.7954345 , -0.31524017, -0.27672288,\n",
       "        0.7578872 , -0.12999505, -0.02418061, -0.12232333, -0.27238017,\n",
       "        0.37948892, -0.2591419 , -0.39219004, -0.93379134, -0.21573642,\n",
       "       -0.39183158,  0.04825225, -0.6553469 ,  0.22990817, -0.83931345,\n",
       "       -0.25721112, -0.5082705 , -0.27275336, -0.6778431 , -0.0312448 ,\n",
       "       -0.258727  , -1.0193454 , -0.09287152, -1.0364486 ,  0.18711726,\n",
       "       -0.02316386,  0.16145718,  0.40200177, -0.06119288,  0.45689508,\n",
       "       -0.25230432, -0.18763053,  0.3498493 ,  0.2297816 ,  0.518836  ,\n",
       "        0.00640096, -0.321703  , -0.47322124,  0.0438311 ,  0.4592798 ,\n",
       "       -0.20024228, -0.12389583,  0.18535109,  0.6870939 , -0.22749336,\n",
       "        0.12906367,  0.43048757,  0.18545315, -0.2656622 , -0.52783275,\n",
       "        0.21063216,  0.46822497, -0.05891539, -0.14233775, -0.06867008,\n",
       "        0.1657313 , -0.4097747 ,  0.20666826, -0.0837974 ,  0.44584224,\n",
       "        0.33898976, -0.43415567, -0.16992821, -0.13781449, -0.46678224,\n",
       "       -0.19461308,  0.01601227,  0.28594196,  0.5600054 , -0.39431787,\n",
       "        0.00170437, -0.07209121, -0.4443316 ,  0.10467951, -0.16335262,\n",
       "        0.35595322, -0.00434245, -0.6409364 ,  0.9922278 , -0.20377368,\n",
       "        0.33041942, -0.34421638, -0.29581225, -0.7244665 , -0.44809765,\n",
       "        0.13166755, -0.1501959 , -0.14914882, -0.06086744, -0.19607806,\n",
       "       -0.8118117 , -0.4985854 , -0.01127127, -0.2655872 ,  0.36552468,\n",
       "       -0.4412067 ,  0.30645984, -0.32908347, -0.75442356, -0.11003103,\n",
       "       -0.15723206, -0.7427352 , -0.36509538, -0.51553744, -0.06692781,\n",
       "        0.3166696 , -0.11132351, -0.34766832, -0.29256618,  0.30615717,\n",
       "       -0.23217934, -0.24990767,  0.260447  ,  0.5477408 , -0.29183283,\n",
       "        0.32243115, -0.527143  ,  0.41395715, -0.7664261 , -0.3883311 ,\n",
       "        0.02696365,  0.6498646 , -0.31857353, -0.61928385,  0.13281916,\n",
       "       -0.17251429, -0.3140853 ,  0.05160924, -0.8057447 , -0.5111481 ,\n",
       "       -0.5128039 ,  0.3412684 ,  0.1695239 ,  0.0409455 , -0.3057783 ,\n",
       "       -0.18299712, -0.41659585,  0.11818798,  0.7101176 ,  0.2789415 ,\n",
       "       -0.4689331 , -0.3086901 , -0.26316106,  0.14342631,  0.45298892,\n",
       "        0.04059133, -0.28130662,  0.07049942,  0.5545157 ,  0.19075689,\n",
       "        0.14736542, -0.36520547, -0.5824941 , -0.46016362,  0.49995044,\n",
       "        0.38254544,  0.5155334 ,  0.11439214, -0.15979914,  0.06849075,\n",
       "       -0.23717606,  0.21372534,  0.37379283, -0.25438815,  0.06162613,\n",
       "       -0.09896641, -0.4408241 ,  0.67356205, -0.57877415, -0.385397  ,\n",
       "        0.1881411 ,  0.12834223, -0.15835074,  0.3485194 , -0.09576216,\n",
       "        0.08594017, -0.5964325 ,  0.09565788, -0.16237606, -0.368716  ,\n",
       "        0.19156045, -0.20813659, -0.6338524 , -0.18520713, -0.12705564,\n",
       "        0.08093415, -0.36616346, -0.03738216,  0.24067354, -0.44039887,\n",
       "       -0.32177925,  0.4246779 ,  0.09646881, -0.66479176,  1.0599653 ,\n",
       "        0.38278875,  0.05499785, -0.600367  , -0.01388774,  0.02980652,\n",
       "        0.17455909,  0.27596852, -0.41542646,  0.05604339, -0.1579874 ,\n",
       "       -0.05416816,  0.02432307, -0.04145063,  0.17590617,  0.04076726],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_w2v_model['借呗']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features for feeding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traditional_features(df):\n",
    "    feature_df = pd.DataFrame()\n",
    "    feature_df['len_q1'] = df.q1.apply(lambda x: len(str(x)))\n",
    "    feature_df['len_q2'] = df.q2.apply(lambda x: len(str(x)))\n",
    "    feature_df['diff_len'] = np.abs(feature_df.len_q1 - feature_df.len_q2)\n",
    "    feature_df['len_q1_valid_tokens'] = df.q1_tokens.apply(lambda x: len(x))\n",
    "    feature_df['len_q2_valid_tokens'] = df.q2_tokens.apply(lambda x: len(x))\n",
    "    feature_df['common_tokens'] = df.apply(lambda x: len(set(x['q1_tokens']).intersection(set(x['q2_tokens']))), axis=1)\n",
    "    feature_df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_token_set_ratio'] = df.apply(lambda x: fuzz.partial_token_set_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    \n",
    "    feature_df['wmd'] = df.apply(lambda x: gensim_w2v_model.wv.wmdistance(x['q1'], x['q2']), axis=1)\n",
    "    feature_df['norm_wmd'] = df.apply(lambda x: norm_gensim_w2v_model.wv.wmdistance(x['q1'], x['q2']), axis=1)\n",
    "    \n",
    "    feature_df['wmd_tokens'] = df.apply(lambda x: gensim_w2v_model.wv.wmdistance(x['q1_tokens'], x['q2_tokens']), axis=1)\n",
    "    feature_df['norm_wmd_tokens'] = df.apply(lambda x: norm_gensim_w2v_model.wv.wmdistance(x['q1_tokens'], x['q2_tokens']), axis=1)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 55s, sys: 1.04 s, total: 5min 56s\n",
      "Wall time: 5min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_feature_df = get_traditional_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_q1_valid_tokens</th>\n",
       "      <th>len_q2_valid_tokens</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>wmd_tokens</th>\n",
       "      <th>norm_wmd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>59503</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>2.089146</td>\n",
       "      <td>0.544929</td>\n",
       "      <td>3.744350</td>\n",
       "      <td>0.724484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28953</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0.999256</td>\n",
       "      <td>0.213689</td>\n",
       "      <td>1.946794</td>\n",
       "      <td>0.350498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57776</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>2.557220</td>\n",
       "      <td>0.602747</td>\n",
       "      <td>7.096186</td>\n",
       "      <td>0.989645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18241</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>2.625573</td>\n",
       "      <td>0.564653</td>\n",
       "      <td>4.325525</td>\n",
       "      <td>0.737729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41539</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>4.255405</td>\n",
       "      <td>0.770281</td>\n",
       "      <td>6.070500</td>\n",
       "      <td>0.957819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       len_q1  len_q2  diff_len  len_q1_valid_tokens  len_q2_valid_tokens  \\\n",
       "59503      19      20         1                    7                    8   \n",
       "28953      11       8         3                    4                    3   \n",
       "57776       7      10         3                    3                    4   \n",
       "18241      10      26        16                    5                   12   \n",
       "41539      18      13         5                    7                    7   \n",
       "\n",
       "       common_tokens  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "59503              2          26                  26   \n",
       "28953              3          84                  88   \n",
       "57776              0          24                  40   \n",
       "18241              2          39                  50   \n",
       "41539              2          32                  38   \n",
       "\n",
       "       fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  \\\n",
       "59503                            26                             26   \n",
       "28953                            88                             88   \n",
       "57776                            40                             40   \n",
       "18241                            50                             50   \n",
       "41539                            32                             32   \n",
       "\n",
       "       fuzz_token_set_ratio  fuzz_token_sort_ratio       wmd  norm_wmd  \\\n",
       "59503                    26                     26  2.089146  0.544929   \n",
       "28953                    84                     84  0.999256  0.213689   \n",
       "57776                    24                     24  2.557220  0.602747   \n",
       "18241                    39                     39  2.625573  0.564653   \n",
       "41539                    19                     19  4.255405  0.770281   \n",
       "\n",
       "       wmd_tokens  norm_wmd_tokens  \n",
       "59503    3.744350         0.724484  \n",
       "28953    1.946794         0.350498  \n",
       "57776    7.096186         0.989645  \n",
       "18241    4.325525         0.737729  \n",
       "41539    6.070500         0.957819  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_tokens2vec(tokens, model):\n",
    "    M = []\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            M.append(model[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "def get_gensim_vec(df, model):\n",
    "    q1_vectors = np.zeros((df.shape[0], 300))\n",
    "\n",
    "    for i, q in enumerate(tqdm_notebook(df.q1_tokens.values)):\n",
    "        q1_vectors[i, :] = _mean_tokens2vec(q, model)\n",
    "\n",
    "    q2_vectors  = np.zeros((df.shape[0], 300))\n",
    "    for i, q in enumerate(tqdm_notebook(df.q2_tokens.values)):\n",
    "        q2_vectors[i, :] = _mean_tokens2vec(q, model)\n",
    "    return q1_vectors, q2_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_features(q1v, q2v):\n",
    "    df = pd.DataFrame()\n",
    "    df['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['skew_q1vec'] = [skew(x) for x in np.nan_to_num(q1v)]\n",
    "    df['skew_q2vec'] = [skew(x) for x in np.nan_to_num(q2v)]\n",
    "    df['kur_q1vec'] = [kurtosis(x) for x in np.nan_to_num(q1v)]\n",
    "    df['kur_q2vec'] = [kurtosis(x) for x in np.nan_to_num(q2v)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11fed800d345559e2426f3afaa8ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e4fa8fce5d44f0afd9b1409ea6ed52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_q1_vec, train_df_q2_vec = get_gensim_vec(train_df, gensim_w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/anaconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:1178: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 4s, sys: 1.81 s, total: 1min 6s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_distance_df = get_distance_features(train_df_q1_vec, train_df_q2_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model input dataframe with label and features columns.\n",
    "train_input_df = pd.concat([train_df['label'], train_feature_df, train_distance_df], axis=1)\n",
    "\n",
    "# Replace all infinite value as nan.\n",
    "train_input_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                            False\n",
       "len_q1                           False\n",
       "len_q2                           False\n",
       "diff_len                         False\n",
       "len_q1_valid_tokens              False\n",
       "len_q2_valid_tokens              False\n",
       "common_tokens                    False\n",
       "fuzz_ratio                       False\n",
       "fuzz_partial_ratio               False\n",
       "fuzz_partial_token_set_ratio     False\n",
       "fuzz_partial_token_sort_ratio    False\n",
       "fuzz_token_set_ratio             False\n",
       "fuzz_token_sort_ratio            False\n",
       "wmd                               True\n",
       "norm_wmd                          True\n",
       "wmd_tokens                        True\n",
       "norm_wmd_tokens                   True\n",
       "cosine_distance                   True\n",
       "cityblock_distance               False\n",
       "jaccard_distance                 False\n",
       "canberra_distance                False\n",
       "euclidean_distance               False\n",
       "minkowski_distance               False\n",
       "braycurtis_distance               True\n",
       "skew_q1vec                       False\n",
       "skew_q2vec                       False\n",
       "kur_q1vec                        False\n",
       "kur_q2vec                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nan(null)\n",
    "train_input_df.isnull().sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check infinite\n",
    "# np.isfinite(train_input_df).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those row with null\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['cosine_distance'])]\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['braycurtis_distance'])]\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['wmd'])]\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['norm_wmd'])]\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['wmd_tokens'])]\n",
    "train_input_df = train_input_df[pd.notnull(train_input_df['norm_wmd_tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and label columns\n",
    "x_col = [col for col in train_input_df.columns if col != 'label']\n",
    "y_col = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_input_df[x_col]\n",
    "y = train_input_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some baseline models\n",
    "- SVC\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC classifier.\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14940   162]\n",
      " [ 3221   121]]\n",
      "\n",
      "F1 score 0.06675862068965517\n",
      "Accuracy 0.8165799175883757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90     15102\n",
      "           1       0.43      0.04      0.07      3342\n",
      "\n",
      "    accuracy                           0.82     18444\n",
      "   macro avg       0.63      0.51      0.48     18444\n",
      "weighted avg       0.75      0.82      0.75     18444\n",
      "\n",
      "CPU times: user 5min 28s, sys: 2.99 s, total: 5min 31s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_clf = SVC(gamma='auto')\n",
    "svc_clf.fit(X_train, y_train)\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC without finetune got 0.81 accuracy but only 0.06 F1 score. The recall is very low (0.04) for label 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14670   432]\n",
      " [ 2828   514]]\n",
      "\n",
      "F1 score 0.23973880597014927\n",
      "Accuracy 0.8232487529819996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     15102\n",
      "           1       0.54      0.15      0.24      3342\n",
      "\n",
      "    accuracy                           0.82     18444\n",
      "   macro avg       0.69      0.56      0.57     18444\n",
      "weighted avg       0.78      0.82      0.78     18444\n",
      "\n",
      "CPU times: user 30.9 s, sys: 271 ms, total: 31.1 s\n",
      "Wall time: 31.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# xgboost classifier\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost got 0.82 acc and got 0.239 F1 score which it's much better than SVC(without tunning). The recall for label 1 is still rather low with 0.15. May try to handle the unbalance classes distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to handle the imbalance data\n",
    "Upsample data with label == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_to_upsampled_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    35112\n",
      "0    35112\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority = ready_to_upsampled_df[ready_to_upsampled_df.label==0]\n",
    "df_minority = ready_to_upsampled_df[ready_to_upsampled_df.label==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "upsampled_df = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "print(upsampled_df.label.value_counts())\n",
    "X_train = upsampled_df[x_col]\n",
    "y_train = upsampled_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_q1_valid_tokens</th>\n",
       "      <th>len_q2_valid_tokens</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>33418</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130.852996</td>\n",
       "      <td>0.627109</td>\n",
       "      <td>0.283735</td>\n",
       "      <td>0.331299</td>\n",
       "      <td>-0.227624</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.191222</td>\n",
       "      <td>0.211301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50787</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172.853957</td>\n",
       "      <td>0.968921</td>\n",
       "      <td>0.433302</td>\n",
       "      <td>0.559625</td>\n",
       "      <td>-0.019332</td>\n",
       "      <td>0.042006</td>\n",
       "      <td>0.666470</td>\n",
       "      <td>0.310729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8337</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132.802012</td>\n",
       "      <td>0.643083</td>\n",
       "      <td>0.291153</td>\n",
       "      <td>0.330427</td>\n",
       "      <td>0.071679</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>-0.506822</td>\n",
       "      <td>-0.250350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1702</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.936358</td>\n",
       "      <td>0.515693</td>\n",
       "      <td>0.238553</td>\n",
       "      <td>0.258521</td>\n",
       "      <td>-0.042675</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>-0.093799</td>\n",
       "      <td>-0.237790</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7188</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.647931</td>\n",
       "      <td>0.362148</td>\n",
       "      <td>0.166803</td>\n",
       "      <td>0.179454</td>\n",
       "      <td>-0.226362</td>\n",
       "      <td>-0.111589</td>\n",
       "      <td>0.035104</td>\n",
       "      <td>0.117231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       len_q1  len_q2  diff_len  len_q1_valid_tokens  len_q2_valid_tokens  \\\n",
       "33418      10      19         9                    5                    9   \n",
       "50787       8      13         5                    4                    5   \n",
       "8337       20      10        10                    8                    4   \n",
       "1702       10      14         4                    5                    6   \n",
       "7188       12      29        17                    6                   13   \n",
       "\n",
       "       common_tokens  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "33418              4          28                  40   \n",
       "50787              1          29                  29   \n",
       "8337               2          60                  50   \n",
       "1702               3          33                  40   \n",
       "7188               5          49                  83   \n",
       "\n",
       "       fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  ...  \\\n",
       "33418                            40                             40  ...   \n",
       "50787                            29                             29  ...   \n",
       "8337                             50                             50  ...   \n",
       "1702                             40                             40  ...   \n",
       "7188                             83                             83  ...   \n",
       "\n",
       "       jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "33418               1.0         130.852996            0.627109   \n",
       "50787               1.0         172.853957            0.968921   \n",
       "8337                1.0         132.802012            0.643083   \n",
       "1702                1.0         112.936358            0.515693   \n",
       "7188                1.0          92.647931            0.362148   \n",
       "\n",
       "       minkowski_distance  braycurtis_distance  skew_q1vec  skew_q2vec  \\\n",
       "33418            0.283735             0.331299   -0.227624    0.016756   \n",
       "50787            0.433302             0.559625   -0.019332    0.042006   \n",
       "8337             0.291153             0.330427    0.071679    0.018534   \n",
       "1702             0.238553             0.258521   -0.042675    0.080588   \n",
       "7188             0.166803             0.179454   -0.226362   -0.111589   \n",
       "\n",
       "       kur_q1vec  kur_q2vec  label  \n",
       "33418   0.191222   0.211301      0  \n",
       "50787   0.666470   0.310729      0  \n",
       "8337   -0.506822  -0.250350      0  \n",
       "1702   -0.093799  -0.237790      0  \n",
       "7188    0.035104   0.117231      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14670   432]\n",
      " [ 2828   514]]\n",
      "\n",
      "F1 score 0.21446563512054695\n",
      "Accuracy 0.763283452613316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     15102\n",
      "           1       0.27      0.18      0.21      3342\n",
      "\n",
      "    accuracy                           0.76     18444\n",
      "   macro avg       0.55      0.54      0.54     18444\n",
      "weighted avg       0.73      0.76      0.74     18444\n",
      "\n",
      "CPU times: user 15min 32s, sys: 7.5 s, total: 15min 39s\n",
      "Wall time: 15min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_clf = SVC(gamma='auto')\n",
    "svc_clf.fit(X_train, y_train)\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVC(no tunning), after upsampled the traning set from 1:5 to 1:5, F1 score raise from 0.066 to 0.21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13842  1260]\n",
      " [ 2248  1094]]\n",
      "\n",
      "F1 score 0.3841292134831461\n",
      "Accuracy 0.8098026458468879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     15102\n",
      "           1       0.46      0.33      0.38      3342\n",
      "\n",
      "    accuracy                           0.81     18444\n",
      "   macro avg       0.66      0.62      0.64     18444\n",
      "weighted avg       0.79      0.81      0.80     18444\n",
      "\n",
      "CPU times: user 55 s, sys: 522 ms, total: 55.5 s\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For xgboost, after upsampled the traning set from 1:5 to 1:5, F1 score raise from 0.239 to 0.384.  \n",
    "Also the roc_auc_score for xgboost is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6219581174762067"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
