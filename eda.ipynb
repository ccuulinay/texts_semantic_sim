{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./data/train.txt\"\n",
    "test_file = \"./data/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data file\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50220\n",
      "1    11266\n",
      "Name: label, dtype: int64\n",
      "0    25169\n",
      "1     5575\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(train_df.info())\n",
    "print(train_df.label.value_counts())\n",
    "# print(test_df.info())\n",
    "print(test_df.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*相似的（label=1）的数量约为不相似的（label=0）的数量的1/5，样本不均衡，不过暂时不考虑。*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>如何得知关闭借呗</td>\n",
       "      <td>想永久关闭借呗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>花呗扫码付钱</td>\n",
       "      <td>二维码扫描可以用花呗吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>花呗逾期后不能分期吗</td>\n",
       "      <td>我这个 逾期后还完了 最低还款 后 能分期吗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>花呗分期清空</td>\n",
       "      <td>花呗分期查询</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>借呗逾期短信通知</td>\n",
       "      <td>如何购买花呗短信通知</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           q1                      q2  label\n",
       "0    如何得知关闭借呗                 想永久关闭借呗      0\n",
       "1      花呗扫码付钱             二维码扫描可以用花呗吗      0\n",
       "2  花呗逾期后不能分期吗  我这个 逾期后还完了 最低还款 后 能分期吗      0\n",
       "3      花呗分期清空                  花呗分期查询      0\n",
       "4    借呗逾期短信通知              如何购买花呗短信通知      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in stopwords from web EDA\n",
    "with open(\"./data/stop_words.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    stop_words_list = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in spelling correction from web EDA\n",
    "with open(\"./data/spelling_corrections.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    spell_chk = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.556 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "jieba.load_userdict(\"./data/dict_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_n_seq(text):\n",
    "    for token_str,replac_str in spell_chk.items():\n",
    "        text = text.replace(token_str, replac_str)\n",
    "        \n",
    "    tokens = [t for t in jieba.cut(text.strip()) if t not in stop_words_list]\n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 30.7 ms, total: 13.8 s\n",
      "Wall time: 13.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['q1_tokens'] = train_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "train_df['q2_tokens'] = train_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q1_tokens'] = test_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q2_tokens'] = test_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>label</th>\n",
       "      <th>q1_tokens</th>\n",
       "      <th>q2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17641</td>\n",
       "      <td>如何才能让蚂蚁借呗重新恢复额度</td>\n",
       "      <td>蚂蚁借呗还款成功后没恢复额度</td>\n",
       "      <td>0</td>\n",
       "      <td>[如何, 才能, 让, 蚂蚁借呗, 重新, 恢复, 额度]</td>\n",
       "      <td>[蚂蚁借呗, 还款, 成功, 没, 恢复, 额度]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20682</td>\n",
       "      <td>我的借呗为什么不能正常使用了</td>\n",
       "      <td>我的蚂蚁借呗为什么用不了</td>\n",
       "      <td>0</td>\n",
       "      <td>[借呗, 为什么, 不能, 正常, 使用]</td>\n",
       "      <td>[蚂蚁借呗, 为什么, 用不了]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43083</td>\n",
       "      <td>一个身份证只能开一个手机号的花呗吗</td>\n",
       "      <td>公司手机已绑订我的身份证，已开通花呗，自己新办手机号也是绑定本人身份证，还能开通花呗吗</td>\n",
       "      <td>1</td>\n",
       "      <td>[一个, 身份证, 只能, 开, 一个, 手机号, 花呗]</td>\n",
       "      <td>[公司, 手机, 已, 绑, 订, 身份证, 已, 开通, 花呗, 自己, 新办, 手机号,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9428</td>\n",
       "      <td>花呗和信用卡收款。是怎么收费</td>\n",
       "      <td>花呗收款的手续费</td>\n",
       "      <td>0</td>\n",
       "      <td>[花呗, 信用度, 卡, 收款, 是, 怎么, 收费]</td>\n",
       "      <td>[花呗, 收款, 手续费]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32099</td>\n",
       "      <td>借呗已还怎么还有负面记录消息来</td>\n",
       "      <td>蚂蚁花呗有负面信息是怎么回事</td>\n",
       "      <td>1</td>\n",
       "      <td>[借呗, 已, 怎么, 还有, 负面, 记录, 消息, 来]</td>\n",
       "      <td>[蚂蚁花呗, 有, 负面, 信息, 是]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      q1                                           q2  label  \\\n",
       "17641    如何才能让蚂蚁借呗重新恢复额度                               蚂蚁借呗还款成功后没恢复额度      0   \n",
       "20682     我的借呗为什么不能正常使用了                                 我的蚂蚁借呗为什么用不了      0   \n",
       "43083  一个身份证只能开一个手机号的花呗吗  公司手机已绑订我的身份证，已开通花呗，自己新办手机号也是绑定本人身份证，还能开通花呗吗      1   \n",
       "9428      花呗和信用卡收款。是怎么收费                                     花呗收款的手续费      0   \n",
       "32099    借呗已还怎么还有负面记录消息来                               蚂蚁花呗有负面信息是怎么回事      1   \n",
       "\n",
       "                            q1_tokens  \\\n",
       "17641   [如何, 才能, 让, 蚂蚁借呗, 重新, 恢复, 额度]   \n",
       "20682           [借呗, 为什么, 不能, 正常, 使用]   \n",
       "43083   [一个, 身份证, 只能, 开, 一个, 手机号, 花呗]   \n",
       "9428      [花呗, 信用度, 卡, 收款, 是, 怎么, 收费]   \n",
       "32099  [借呗, 已, 怎么, 还有, 负面, 记录, 消息, 来]   \n",
       "\n",
       "                                               q2_tokens  \n",
       "17641                          [蚂蚁借呗, 还款, 成功, 没, 恢复, 额度]  \n",
       "20682                                   [蚂蚁借呗, 为什么, 用不了]  \n",
       "43083  [公司, 手机, 已, 绑, 订, 身份证, 已, 开通, 花呗, 自己, 新办, 手机号,...  \n",
       "9428                                       [花呗, 收款, 手续费]  \n",
       "32099                               [蚂蚁花呗, 有, 负面, 信息, 是]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    61486.000000\n",
      "mean         5.720782\n",
      "std          2.483575\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         38.000000\n",
      "Name: q1_tokens, dtype: float64\n",
      "count    61486.000000\n",
      "mean         5.724946\n",
      "std          2.482776\n",
      "min          0.000000\n",
      "25%          4.000000\n",
      "50%          5.000000\n",
      "75%          7.000000\n",
      "max         40.000000\n",
      "Name: q2_tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the tokens length distribution\n",
    "print(train_df.q1_tokens.str.len().describe())\n",
    "print(train_df.q2_tokens.str.len().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traditional methods to get features like word count, common tokens and various distances, etc. Then fit to traditional Machine Learning models to see how is it.\n",
    "## metrics: F1 score and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try gensim word2vec first to get word to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "texts_q1_test = [token for token in test_df['q1_tokens'].tolist()]\n",
    "texts_q2_test = [token for token in test_df['q2_tokens'].tolist()]\n",
    "\n",
    "texts_q1_train = [token for token in train_df['q1_tokens'].tolist()]\n",
    "texts_q2_train = [token for token in train_df['q2_tokens'].tolist()]\n",
    "\n",
    "texts.extend(texts_q1_test)\n",
    "texts.extend(texts_q2_test)\n",
    "texts.extend(texts_q1_train)\n",
    "texts.extend(texts_q2_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 86.1 ms, total: 13.6 s\n",
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gensim_w2v_model = word2vec.Word2Vec(sentences=texts,size=300,window=2,min_count=3,workers=2)\n",
    "norm_gensim_w2v_model = word2vec.Word2Vec(sentences=texts,size=300,window=2,min_count=3,workers=2)\n",
    "norm_gensim_w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 4.44445685e-02,  2.73065835e-01,  2.52912194e-01,  9.98831093e-02,\n",
       "       -5.26858168e-03, -7.32327163e-01, -1.72038257e-01,  6.28688157e-01,\n",
       "       -3.58915418e-01, -4.23523009e-01,  1.04867674e-01,  1.43855929e-01,\n",
       "       -1.58883799e-02, -6.84987307e-02,  7.94039607e-01,  3.15837972e-02,\n",
       "       -1.15724072e-01, -2.36712068e-01, -1.24650836e-01, -5.91551773e-02,\n",
       "        3.90599161e-01, -3.87325108e-01, -5.00738561e-01, -8.35867301e-02,\n",
       "        3.01632285e-01,  9.87665504e-02, -4.05652106e-01, -3.91770571e-01,\n",
       "       -4.27176893e-01, -5.03384829e-01,  2.37702787e-01, -6.74819827e-01,\n",
       "       -1.53576404e-01, -1.77623071e-02, -1.43175974e-01,  1.58097432e-03,\n",
       "        1.28692597e-01, -8.18581045e-01, -5.08349985e-02, -6.74639195e-02,\n",
       "       -8.46400857e-01,  1.80441961e-01,  1.11271538e-01,  6.80248082e-01,\n",
       "        6.69473946e-01,  6.80518210e-01,  1.65595621e-01,  1.70601696e-01,\n",
       "       -3.03341091e-01, -1.53055146e-01,  5.77953607e-02,  3.44372749e-01,\n",
       "        7.41366446e-02, -1.84576005e-01,  3.10207486e-01, -3.05215716e-01,\n",
       "       -1.38155133e-01, -1.82826072e-01, -8.33715647e-02, -4.63038594e-01,\n",
       "        3.82670909e-02,  3.38807195e-01, -3.19857806e-01,  4.92356658e-01,\n",
       "        2.07980916e-01, -3.69685173e-01,  7.68038258e-02, -2.95376003e-01,\n",
       "       -7.59153724e-01,  7.07500875e-01, -3.92546207e-01, -4.68199611e-01,\n",
       "       -7.48016164e-02, -3.18187982e-01,  2.43948251e-01, -3.01051527e-01,\n",
       "        6.71604812e-01, -1.32070512e-01,  1.88987121e-01,  5.47201897e-04,\n",
       "        6.61308989e-02, -3.44986439e-01,  3.96961749e-01,  4.93615150e-01,\n",
       "       -1.65938079e-01,  2.49708727e-01, -3.12490851e-01,  4.75968629e-01,\n",
       "       -8.46974626e-02, -6.03920110e-02, -4.37355042e-01, -1.20446300e-02,\n",
       "        5.81715882e-01,  2.04742193e-01,  2.26843029e-01, -2.01906681e-01,\n",
       "       -6.96889013e-02,  2.02274442e-01,  2.36654207e-02, -3.04012537e-01,\n",
       "        1.82500899e-01,  5.43766737e-01, -2.63126880e-01, -2.08902866e-01,\n",
       "       -7.62858391e-01, -1.06819594e+00, -8.16555202e-01,  1.67883471e-01,\n",
       "       -1.27088830e-01, -8.62872154e-02, -5.07190168e-01, -9.16763097e-02,\n",
       "        1.17028281e-01,  4.87164885e-01,  3.15843105e-01,  5.47114193e-01,\n",
       "       -6.52316332e-01, -3.97478253e-01,  3.24007183e-01,  1.61606185e-02,\n",
       "       -6.67271689e-02,  2.25752026e-01, -1.88899189e-01,  4.23380822e-01,\n",
       "        2.71262407e-01, -9.90351755e-03, -2.67917644e-02, -4.26374942e-01,\n",
       "        2.40723893e-01,  1.55093774e-01, -8.74835346e-03,  1.79249361e-01,\n",
       "       -4.33386803e-01, -1.93397522e-01, -2.14946926e-01,  1.66280672e-01,\n",
       "       -1.10881291e-01,  2.91999310e-01, -4.81288761e-01,  6.29743282e-03,\n",
       "        4.02825147e-01,  2.56161034e-01, -6.00585580e-01, -1.53377026e-01,\n",
       "       -3.63303691e-01, -1.01532742e-01,  7.41690993e-01, -4.74624574e-01,\n",
       "        8.38706642e-02, -5.15487552e-01,  3.18821728e-01,  3.81958038e-01,\n",
       "        6.90023005e-01, -3.86046141e-01, -1.55494258e-01,  9.21380699e-01,\n",
       "        2.13776901e-01,  1.21010328e-02,  5.33853114e-01,  1.63576901e-01,\n",
       "        7.69796669e-02,  1.26835495e-01, -8.70410323e-01,  1.40696824e-01,\n",
       "        1.54888734e-01,  4.78535235e-01,  7.22603425e-02,  3.47234279e-01,\n",
       "       -1.51974028e-02,  4.09996003e-01, -4.92056817e-01,  1.73595510e-02,\n",
       "        6.00314558e-01, -1.35286421e-01, -2.77931094e-01, -5.72668850e-01,\n",
       "       -1.08494103e-01, -5.98834693e-01, -4.71921377e-02, -3.88923258e-01,\n",
       "       -3.62912612e-03, -5.38686216e-01, -5.07470965e-01, -3.15959811e-01,\n",
       "        1.04699068e-01, -1.77039672e-02, -1.39648169e-01,  1.57417968e-01,\n",
       "       -3.20507079e-01,  2.74541885e-01, -2.67621189e-01, -1.36561826e-01,\n",
       "       -6.46362066e-01, -1.72031179e-01, -4.02421743e-01,  6.88331962e-01,\n",
       "       -2.84371644e-01, -5.43230139e-02, -7.78326452e-01, -5.62870026e-01,\n",
       "        2.23978877e-01,  4.58923310e-01,  2.45359942e-01, -5.66296689e-02,\n",
       "       -3.58054847e-01,  6.15812182e-01,  2.23317608e-01, -1.71398278e-02,\n",
       "       -8.51520360e-01,  2.84072727e-01, -3.63556176e-01, -7.57499099e-01,\n",
       "       -7.84146011e-01,  7.71137178e-01,  4.63767678e-01,  3.17957997e-01,\n",
       "       -4.36014086e-01, -1.00568555e-01, -3.13800387e-02, -2.31022000e-01,\n",
       "        6.22475743e-01,  9.81668159e-02,  2.97520846e-01,  1.19541265e-01,\n",
       "        1.35791138e-01, -1.02419205e-01, -4.93183076e-01, -4.73625302e-01,\n",
       "        4.43529695e-01,  2.93739766e-01,  4.97195631e-01,  5.65413296e-01,\n",
       "       -2.01301008e-01,  5.83373785e-01, -1.01564236e-01,  3.41783911e-01,\n",
       "        2.78310388e-01, -4.53942895e-01,  3.06570441e-01,  2.08887085e-01,\n",
       "       -3.09187412e-01, -3.46740603e-01, -1.63929492e-01, -5.63085854e-01,\n",
       "       -2.07728639e-01, -5.26492536e-01, -3.21429551e-01, -7.68318117e-01,\n",
       "        4.98042613e-01, -8.90895128e-02,  1.46814128e-02,  1.66500896e-01,\n",
       "       -7.54610360e-01,  1.90606162e-01,  2.48417109e-01, -3.12263668e-02,\n",
       "        4.71749067e-01,  5.30189097e-01,  9.54146404e-03, -3.31154257e-01,\n",
       "        5.00732601e-01,  1.62486956e-01, -8.33846152e-01, -1.92779943e-01,\n",
       "       -3.34303707e-01,  8.39452520e-02, -2.69939125e-01, -1.15721568e-01,\n",
       "       -3.71550143e-01, -1.42928168e-01, -3.82081211e-01, -1.89779997e-01,\n",
       "        7.16072246e-02, -9.99360621e-01,  1.04811445e-01,  3.93578023e-01,\n",
       "       -7.98899531e-02,  6.82425201e-02,  2.08454609e-01,  3.46659631e-01,\n",
       "        9.61088538e-02,  5.81435300e-02,  2.30408877e-01, -5.64032674e-01,\n",
       "       -1.56993493e-01, -3.39984298e-02, -3.60645384e-01, -2.57321354e-02,\n",
       "       -4.11596924e-01, -7.54017651e-01,  6.73479676e-01,  5.18913686e-01,\n",
       "       -3.77452910e-01, -1.12755485e-01, -1.36618331e-01,  9.30870399e-02,\n",
       "       -6.47817627e-02, -2.17897996e-01, -7.01657474e-01, -6.85817450e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_w2v_model['借呗']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build features for feeding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from fuzzywuzzy import fuzz\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traditional_features(df):\n",
    "    feature_df = pd.DataFrame()\n",
    "    feature_df['len_q1'] = df.q1.apply(lambda x: len(str(x)))\n",
    "    feature_df['len_q2'] = df.q2.apply(lambda x: len(str(x)))\n",
    "    feature_df['diff_len'] = np.abs(feature_df.len_q1 - feature_df.len_q2)\n",
    "    feature_df['len_q1_valid_tokens'] = df.q1_tokens.apply(lambda x: len(x))\n",
    "    feature_df['len_q2_valid_tokens'] = df.q2_tokens.apply(lambda x: len(x))\n",
    "    feature_df['common_tokens'] = df.apply(lambda x: len(set(x['q1_tokens']).intersection(set(x['q2_tokens']))), axis=1)\n",
    "    feature_df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_token_set_ratio'] = df.apply(lambda x: fuzz.partial_token_set_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    feature_df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['q1']), str(x['q2'])), axis=1)\n",
    "    \n",
    "    feature_df['wmd'] = df.apply(lambda x: gensim_w2v_model.wv.wmdistance(x['q1'], x['q2']), axis=1)\n",
    "    feature_df['norm_wmd'] = df.apply(lambda x: norm_gensim_w2v_model.wv.wmdistance(x['q1'], x['q2']), axis=1)\n",
    "    \n",
    "    feature_df['wmd_tokens'] = df.apply(lambda x: gensim_w2v_model.wv.wmdistance(x['q1_tokens'], x['q2_tokens']), axis=1)\n",
    "    feature_df['norm_wmd_tokens'] = df.apply(lambda x: norm_gensim_w2v_model.wv.wmdistance(x['q1_tokens'], x['q2_tokens']), axis=1)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 33s, sys: 473 ms, total: 4min 33s\n",
      "Wall time: 4min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_feature_df = get_traditional_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_q1_valid_tokens</th>\n",
       "      <th>len_q2_valid_tokens</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>wmd</th>\n",
       "      <th>norm_wmd</th>\n",
       "      <th>wmd_tokens</th>\n",
       "      <th>norm_wmd_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4907</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>2.864579</td>\n",
       "      <td>0.796665</td>\n",
       "      <td>2.135019</td>\n",
       "      <td>0.468668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46002</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>3.487158</td>\n",
       "      <td>0.698987</td>\n",
       "      <td>4.367845</td>\n",
       "      <td>0.874672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6734</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>3.263695</td>\n",
       "      <td>0.622171</td>\n",
       "      <td>4.264730</td>\n",
       "      <td>0.659276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18556</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>3.281595</td>\n",
       "      <td>0.632771</td>\n",
       "      <td>2.947248</td>\n",
       "      <td>0.583106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2415</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>1.941517</td>\n",
       "      <td>0.282135</td>\n",
       "      <td>3.849705</td>\n",
       "      <td>0.525148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       len_q1  len_q2  diff_len  len_q1_valid_tokens  len_q2_valid_tokens  \\\n",
       "4907        9       6         3                    4                    3   \n",
       "46002       9      15         6                    3                    7   \n",
       "6734       13      14         1                    6                    5   \n",
       "18556       8      10         2                    5                    6   \n",
       "2415        9       9         0                    4                    5   \n",
       "\n",
       "       common_tokens  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "4907               2          53                  33   \n",
       "46002              1          33                  31   \n",
       "6734               2          52                  56   \n",
       "18556              3          56                  62   \n",
       "2415               3          67                  67   \n",
       "\n",
       "       fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  \\\n",
       "4907                             33                             33   \n",
       "46002                            24                             24   \n",
       "6734                             56                             56   \n",
       "18556                            62                             62   \n",
       "2415                             67                             67   \n",
       "\n",
       "       fuzz_token_set_ratio  fuzz_token_sort_ratio       wmd  norm_wmd  \\\n",
       "4907                     53                     53  2.864579  0.796665   \n",
       "46002                    17                     17  3.487158  0.698987   \n",
       "6734                     52                     52  3.263695  0.622171   \n",
       "18556                    56                     56  3.281595  0.632771   \n",
       "2415                     67                     67  1.941517  0.282135   \n",
       "\n",
       "       wmd_tokens  norm_wmd_tokens  \n",
       "4907     2.135019         0.468668  \n",
       "46002    4.367845         0.874672  \n",
       "6734     4.264730         0.659276  \n",
       "18556    2.947248         0.583106  \n",
       "2415     3.849705         0.525148  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mean_tokens2vec(tokens, model):\n",
    "    M = []\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            M.append(model[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())\n",
    "\n",
    "def get_gensim_vec(df, model):\n",
    "    q1_vectors = np.zeros((df.shape[0], 300))\n",
    "\n",
    "    for i, q in enumerate(tqdm_notebook(df.q1_tokens.values)):\n",
    "        q1_vectors[i, :] = _mean_tokens2vec(q, model)\n",
    "\n",
    "    q2_vectors  = np.zeros((df.shape[0], 300))\n",
    "    for i, q in enumerate(tqdm_notebook(df.q2_tokens.values)):\n",
    "        q2_vectors[i, :] = _mean_tokens2vec(q, model)\n",
    "    return q1_vectors, q2_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_features(q1v, q2v):\n",
    "    df = pd.DataFrame()\n",
    "    df['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(q1v), np.nan_to_num(q2v))]\n",
    "    df['skew_q1vec'] = [skew(x) for x in np.nan_to_num(q1v)]\n",
    "    df['skew_q2vec'] = [skew(x) for x in np.nan_to_num(q2v)]\n",
    "    df['kur_q1vec'] = [kurtosis(x) for x in np.nan_to_num(q1v)]\n",
    "    df['kur_q2vec'] = [kurtosis(x) for x in np.nan_to_num(q2v)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8554bf173644c28b3b0606635a706f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a21c63b8e6496ba08360f27defb43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61486), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_q1_vec, train_df_q2_vec = get_gensim_vec(train_df, gensim_w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/scipy/spatial/distance.py:1178: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.5 s, sys: 990 ms, total: 55.5 s\n",
      "Wall time: 54.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_distance_df = get_distance_features(train_df_q1_vec, train_df_q2_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model input dataframe with label and features columns.\n",
    "train_input_df = pd.concat([train_df['label'], train_feature_df, train_distance_df], axis=1)\n",
    "\n",
    "# Replace all infinite value as nan.\n",
    "train_input_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label                            False\n",
       "len_q1                           False\n",
       "len_q2                           False\n",
       "diff_len                         False\n",
       "len_q1_valid_tokens              False\n",
       "len_q2_valid_tokens              False\n",
       "common_tokens                    False\n",
       "fuzz_ratio                       False\n",
       "fuzz_partial_ratio               False\n",
       "fuzz_partial_token_set_ratio     False\n",
       "fuzz_partial_token_sort_ratio    False\n",
       "fuzz_token_set_ratio             False\n",
       "fuzz_token_sort_ratio            False\n",
       "wmd                              False\n",
       "norm_wmd                         False\n",
       "wmd_tokens                       False\n",
       "norm_wmd_tokens                  False\n",
       "cosine_distance                  False\n",
       "cityblock_distance               False\n",
       "jaccard_distance                 False\n",
       "canberra_distance                False\n",
       "euclidean_distance               False\n",
       "minkowski_distance               False\n",
       "braycurtis_distance              False\n",
       "skew_q1vec                       False\n",
       "skew_q2vec                       False\n",
       "kur_q1vec                        False\n",
       "kur_q2vec                        False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check nan(null)\n",
    "train_input_df.isnull().sum() > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check infinite\n",
    "# np.isfinite(train_input_df).all()\n",
    "ori_train_input_df = train_input_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove those row with null\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['cosine_distance'])]\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['braycurtis_distance'])]\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['wmd'])]\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['norm_wmd'])]\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['wmd_tokens'])]\n",
    "# train_input_df = train_input_df[pd.notnull(train_input_df['norm_wmd_tokens'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and label columns\n",
    "x_col = [col for col in train_input_df.columns if col != 'label']\n",
    "y_col = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_input_df[x_col]\n",
    "y = train_input_df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try some baseline models\n",
    "- SVC\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC classifier.\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14940   162]\n",
      " [ 3221   121]]\n",
      "\n",
      "F1 score 0.06675862068965517\n",
      "Accuracy 0.8165799175883757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90     15102\n",
      "           1       0.43      0.04      0.07      3342\n",
      "\n",
      "    accuracy                           0.82     18444\n",
      "   macro avg       0.63      0.51      0.48     18444\n",
      "weighted avg       0.75      0.82      0.75     18444\n",
      "\n",
      "CPU times: user 5min 28s, sys: 2.99 s, total: 5min 31s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_clf = SVC(gamma='auto')\n",
    "svc_clf.fit(X_train, y_train)\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC without finetune got 0.81 accuracy but only 0.06 F1 score. The recall is very low (0.04) for label 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14661   418]\n",
      " [ 2836   531]]\n",
      "\n",
      "F1 score 0.24606116774791473\n",
      "Accuracy 0.8235931909357043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     15079\n",
      "           1       0.56      0.16      0.25      3367\n",
      "\n",
      "    accuracy                           0.82     18446\n",
      "   macro avg       0.70      0.56      0.57     18446\n",
      "weighted avg       0.79      0.82      0.78     18446\n",
      "\n",
      "CPU times: user 23.2 s, sys: 152 ms, total: 23.3 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# xgboost classifier\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost got 0.82 acc and got 0.239 F1 score which it's much better than SVC(without tunning). The recall for label 1 is still rather low with 0.15. May try to handle the unbalance classes distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to handle the imbalance data\n",
    "Upsample data with label == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_to_upsampled_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    35141\n",
      "0    35141\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_majority = ready_to_upsampled_df[ready_to_upsampled_df.label==0]\n",
    "df_minority = ready_to_upsampled_df[ready_to_upsampled_df.label==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "upsampled_df = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "print(upsampled_df.label.value_counts())\n",
    "X_train = upsampled_df[x_col]\n",
    "y_train = upsampled_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_q1_valid_tokens</th>\n",
       "      <th>len_q2_valid_tokens</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27129</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.972577</td>\n",
       "      <td>0.562474</td>\n",
       "      <td>0.252353</td>\n",
       "      <td>0.293040</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.008702</td>\n",
       "      <td>0.032413</td>\n",
       "      <td>-0.137284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45835</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.599768</td>\n",
       "      <td>0.824399</td>\n",
       "      <td>0.376181</td>\n",
       "      <td>0.441109</td>\n",
       "      <td>0.067420</td>\n",
       "      <td>0.192468</td>\n",
       "      <td>-0.276271</td>\n",
       "      <td>-0.251577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33446</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.242950</td>\n",
       "      <td>0.730654</td>\n",
       "      <td>0.319568</td>\n",
       "      <td>0.395178</td>\n",
       "      <td>0.075762</td>\n",
       "      <td>0.039882</td>\n",
       "      <td>-0.371980</td>\n",
       "      <td>-0.425226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8336</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.238877</td>\n",
       "      <td>0.699606</td>\n",
       "      <td>0.313598</td>\n",
       "      <td>0.366224</td>\n",
       "      <td>0.252862</td>\n",
       "      <td>-0.129060</td>\n",
       "      <td>-0.371942</td>\n",
       "      <td>-0.119832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1702</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.027857</td>\n",
       "      <td>0.513289</td>\n",
       "      <td>0.232205</td>\n",
       "      <td>0.263658</td>\n",
       "      <td>-0.012085</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>-0.054914</td>\n",
       "      <td>-0.290441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       len_q1  len_q2  diff_len  len_q1_valid_tokens  len_q2_valid_tokens  \\\n",
       "27129      21      12         9                    8                    5   \n",
       "45835       8      12         4                    3                    4   \n",
       "33446      11      17         6                    5                    6   \n",
       "8336       11       6         5                    5                    3   \n",
       "1702       10      14         4                    5                    6   \n",
       "\n",
       "       common_tokens  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "27129              2          42                  50   \n",
       "45835              1          40                  50   \n",
       "33446              3          36                  38   \n",
       "8336               1          47                  67   \n",
       "1702               3          33                  40   \n",
       "\n",
       "       fuzz_partial_token_set_ratio  fuzz_partial_token_sort_ratio  ...  \\\n",
       "27129                            50                             50  ...   \n",
       "45835                            50                             50  ...   \n",
       "33446                            38                             38  ...   \n",
       "8336                             67                             67  ...   \n",
       "1702                             40                             40  ...   \n",
       "\n",
       "       jaccard_distance  canberra_distance  euclidean_distance  \\\n",
       "27129               1.0         127.972577            0.562474   \n",
       "45835               1.0         152.599768            0.824399   \n",
       "33446               1.0         149.242950            0.730654   \n",
       "8336                1.0         138.238877            0.699606   \n",
       "1702                1.0         120.027857            0.513289   \n",
       "\n",
       "       minkowski_distance  braycurtis_distance  skew_q1vec  skew_q2vec  \\\n",
       "27129            0.252353             0.293040    0.015490    0.008702   \n",
       "45835            0.376181             0.441109    0.067420    0.192468   \n",
       "33446            0.319568             0.395178    0.075762    0.039882   \n",
       "8336             0.313598             0.366224    0.252862   -0.129060   \n",
       "1702             0.232205             0.263658   -0.012085    0.001224   \n",
       "\n",
       "       kur_q1vec  kur_q2vec  label  \n",
       "27129   0.032413  -0.137284      0  \n",
       "45835  -0.276271  -0.251577      0  \n",
       "33446  -0.371980  -0.425226      0  \n",
       "8336   -0.371942  -0.119832      0  \n",
       "1702   -0.054914  -0.290441      0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14670   432]\n",
      " [ 2828   514]]\n",
      "\n",
      "F1 score 0.21446563512054695\n",
      "Accuracy 0.763283452613316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     15102\n",
      "           1       0.27      0.18      0.21      3342\n",
      "\n",
      "    accuracy                           0.76     18444\n",
      "   macro avg       0.55      0.54      0.54     18444\n",
      "weighted avg       0.73      0.76      0.74     18444\n",
      "\n",
      "CPU times: user 15min 32s, sys: 7.5 s, total: 15min 39s\n",
      "Wall time: 15min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svc_clf = SVC(gamma='auto')\n",
    "svc_clf.fit(X_train, y_train)\n",
    "y_pred = svc_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVC(no tunning), after upsampled the traning set from 1:5 to 1:5, F1 score raise from 0.066 to 0.21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22929  2240]\n",
      " [ 3767  1808]]\n",
      "\n",
      "F1 score 0.3757663930167307\n",
      "Accuracy 0.8046122820712984\n",
      "ROC AUC SCORE 0.6176532808617334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     25169\n",
      "           1       0.45      0.32      0.38      5575\n",
      "\n",
      "    accuracy                           0.80     30744\n",
      "   macro avg       0.65      0.62      0.63     30744\n",
      "weighted avg       0.78      0.80      0.79     30744\n",
      "\n",
      "CPU times: user 41 s, sys: 23.9 ms, total: 41 s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "print('ROC AUC SCORE', roc_auc_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For xgboost, after upsampled the traning set from 1:5 to 1:5, F1 score raise from 0.239 to 0.384.  \n",
    "Also the roc_auc_score for xgboost is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = model # From above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c4a94cca0f4e2f994ed6c973c530cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30744), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219627320844442fb3dd464f3e7b2eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30744), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ccuulinay/anaconda3/envs/texts_cls/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 46s, sys: 457 ms, total: 2min 47s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_feature_df = get_traditional_features(test_df)\n",
    "test_df_q1_vec, test_df_q2_vec = get_gensim_vec(test_df, gensim_w2v_model)\n",
    "test_distance_df = get_distance_features(test_df_q1_vec, test_df_q2_vec)\n",
    "test_input_df = pd.concat([test_df['label'], test_feature_df, test_distance_df], axis=1)\n",
    "\n",
    "# Replace all infinite value as nan.\n",
    "test_input_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_input_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_run_test = test_input_df[x_col]\n",
    "y_run_test = test_input_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22929  2240]\n",
      " [ 3767  1808]]\n",
      "\n",
      "F1 score 0.3757663930167307\n",
      "Accuracy 0.8046122820712984\n",
      "ROC AUC SCORE 0.6176532808617334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     25169\n",
      "           1       0.45      0.32      0.38      5575\n",
      "\n",
      "    accuracy                           0.80     30744\n",
      "   macro avg       0.65      0.62      0.63     30744\n",
      "weighted avg       0.78      0.80      0.79     30744\n",
      "\n",
      "CPU times: user 555 ms, sys: 12 ms, total: 567 ms\n",
      "Wall time: 565 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_run_pred = model.predict(X_run_test)\n",
    "cm = confusion_matrix(y_run_test, y_run_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_run_test, y_run_pred))\n",
    "print('Accuracy', accuracy_score(y_run_test, y_run_pred))\n",
    "print('ROC AUC SCORE', roc_auc_score(y_run_test, y_run_pred))\n",
    "print(classification_report(y_run_test, y_run_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result run on test.txt is above, F1 score around 0.37."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
