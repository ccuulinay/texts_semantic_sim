{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"./data/train.txt\"\n",
    "test_file = \"./data/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data file\n",
    "train_df = pd.read_csv(train_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])\n",
    "test_df = pd.read_csv(test_file, sep=\"\\t\", header=None, names=[\"q1\", \"q2\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.559 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Read in stopwords from web EDA\n",
    "with open(\"./data/stop_words.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    stop_words_list = [line.strip() for line in f]\n",
    "    \n",
    "# Read in spelling correction from web EDA\n",
    "with open(\"./data/spelling_corrections.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    spell_chk = json.loads(f.read())\n",
    "    \n",
    "import jieba\n",
    "jieba.load_userdict(\"./data/dict_all.txt\")\n",
    "\n",
    "def preprocessing_n_seq(text):\n",
    "    for token_str,replac_str in spell_chk.items():\n",
    "        text = text.replace(token_str, replac_str)\n",
    "        \n",
    "    tokens = [t for t in jieba.cut(text.strip()) if t not in stop_words_list]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 s, sys: 34.7 ms, total: 13.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['q1_tokens'] = train_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "train_df['q2_tokens'] = train_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q1_tokens'] = test_df['q1'].apply(lambda x: preprocessing_n_seq(x))\n",
    "test_df['q2_tokens'] = test_df['q2'].apply(lambda x: preprocessing_n_seq(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in tencent pretrained word vector\n",
    "tencent_pretrained_vec_loc = \"/data/Tencent_AILab_ChineseEmbedding.txt\"\n",
    "def process_raw_fileline(line, number_dim):\n",
    "    line = line.rstrip().decode('utf8')\n",
    "    pieces = line.rsplit(' ', int(number_dim))\n",
    "    word = pieces[0]\n",
    "    vector = np.asarray([float(v) for v in pieces[1:]], dtype='f')\n",
    "    return word, vector\n",
    "\n",
    "def load_tencent_pretrained_vectors():\n",
    "    from multiprocessing import Pool  # For CPU\n",
    "    from multiprocessing.dummy import Pool as ThreadPool  # For IO\n",
    "    from functools import partial\n",
    "\n",
    "    with open(tencent_pretrained_vec_loc, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        number_row, number_dim = header.split()\n",
    "\n",
    "        pool = Pool(8)\n",
    "        # pool = ThreadPool(8)\n",
    "        process_raw_fileline_100dim = partial(process_raw_fileline, number_dim=number_dim)\n",
    "        wv_set_list = pool.map(process_raw_fileline_100dim, f)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        # print(\"pool done.\")\n",
    "        w2v = dict(wv_set_list)\n",
    "    return w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.3 s, sys: 37.5 s, total: 1min 20s\n",
      "Wall time: 5min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tencent_w2v = load_tencent_pretrained_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.250116, -0.366958,  0.065014,  0.010725,  0.231398, -0.177817,\n",
       "        0.064359, -0.005259,  0.115888,  0.154   ,  0.171935,  0.07247 ,\n",
       "       -0.003175, -0.09248 ,  0.20276 , -0.030792, -0.306991, -0.289693,\n",
       "       -0.055264, -0.189153,  0.122888,  0.081699,  0.017909,  0.158469,\n",
       "        0.147464,  0.079238, -0.224966,  0.145837,  0.182973, -0.149864,\n",
       "       -0.156044,  0.044855, -0.237059,  0.174146, -0.108293, -0.066462,\n",
       "        0.140773,  0.092687, -0.124868, -0.026098,  0.167881, -0.117048,\n",
       "        0.39075 , -0.036812, -0.051702, -0.161367, -0.355791, -0.311515,\n",
       "       -0.090306,  0.084679, -0.184472,  0.090339, -0.098312,  0.256595,\n",
       "        0.292554,  0.274648,  0.039325,  0.150774,  0.239049, -0.011787,\n",
       "       -0.014104,  0.135062,  0.151537, -0.208729, -0.171538,  0.08003 ,\n",
       "       -0.116087,  0.159768, -0.061878, -0.149166, -0.065586,  0.029528,\n",
       "       -0.020271,  0.098718, -0.068513,  0.238489,  0.174631, -0.003655,\n",
       "        0.161002, -0.002617,  0.202535,  0.276254,  0.03933 ,  0.008368,\n",
       "        0.258403, -0.254685, -0.046402,  0.415975, -0.369803, -0.070436,\n",
       "        0.165418,  0.167119,  0.047878,  0.105566, -0.127156,  0.189587,\n",
       "       -0.022974, -0.210112, -0.297339,  0.071683, -0.111609,  0.265368,\n",
       "       -0.108999,  0.247901, -0.434307,  0.216444,  0.033944, -0.551442,\n",
       "       -0.072594,  0.00983 , -0.028967, -0.181977, -0.032623, -0.179671,\n",
       "        0.128933, -0.087196,  0.12034 , -0.221466, -0.200841, -0.218873,\n",
       "        0.277069, -0.366933,  0.003879, -0.027925,  0.069605, -0.057702,\n",
       "       -0.010946, -0.035958,  0.039027,  0.367287,  0.044901,  0.128941,\n",
       "       -0.039109, -0.088411, -0.210587, -0.195746, -0.265087,  0.117322,\n",
       "        0.057173, -0.134257, -0.214258, -0.247163, -0.274339,  0.054974,\n",
       "       -0.111022, -0.567581,  0.212942, -0.222993, -0.027288,  0.198594,\n",
       "       -0.052249,  0.149065, -0.242251, -0.194625, -0.040973, -0.00749 ,\n",
       "        0.168107, -0.079271,  0.263272, -0.370942,  0.190593,  0.015323,\n",
       "        0.115155,  0.074836,  0.307684,  0.204195, -0.105276,  0.298403,\n",
       "        0.151988,  0.045363, -0.128028, -0.065257, -0.150151,  0.13884 ,\n",
       "       -0.07511 ,  0.019008, -0.181566, -0.044517,  0.208922,  0.067851,\n",
       "        0.059112, -0.029587, -0.138191, -0.009103, -0.083886, -0.252082,\n",
       "       -0.224802,  0.450786,  0.100208, -0.050416,  0.050791,  0.095502,\n",
       "       -0.180603,  0.003119,  0.176932,  0.367467, -0.042056, -0.330716,\n",
       "       -0.165911,  0.194028], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tencent_w2v[\"我\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import TransformerMixin\n",
    "import jieba\n",
    "\n",
    "jieba.load_userdict(\"./data/dict_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 20000 8824330\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = np.shape(next(iter(tencent_w2v.values())))[0]\n",
    "MAX_NUM_WORDS = 20000\n",
    "print(EMBEDDING_DIM, MAX_NUM_WORDS, len(tencent_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts(raw_texts):\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup as bs\n",
    "    def bs_unescape_html(text):\n",
    "        return bs(text, \"lxml\").get_text()\n",
    "    def preprocess_text(raw_text):\n",
    "        # text = re.sub(r'\\(.*\\)', '', raw_text)\n",
    "        text = \" \".join(jieba.cut(raw_text))\n",
    "        return bs_unescape_html(text.lower().strip())\n",
    "    \n",
    "    return [preprocess_text(t) for t in raw_texts]\n",
    "\n",
    "\n",
    "class Text2SeqTransformer(Tokenizer, BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        params: num_words: to be a vocab_size of returning tokenzier and dictionary.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def fit(self, texts, y=None):\n",
    "        \"\"\"\n",
    "        params: texts: list of strings\n",
    "        \"\"\"\n",
    "        self.fit_on_texts(texts)\n",
    "        return self\n",
    "\n",
    "    def transform(self, texts, y=None):\n",
    "        return np.array(self.texts_to_sequences(texts))\n",
    "    \n",
    "# Implement a padder transformer base on keras pad_sequences\n",
    "class PaddingTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, maxlen=200):\n",
    "        self.maxlen = maxlen\n",
    "        self.max_index = None\n",
    "    def fit(self, X, y=None):\n",
    "        self.max_index = pad_sequences(X, maxlen=self.maxlen).max()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X = pad_sequences(X, maxlen=self.maxlen)\n",
    "        X[X > self.max_index] = 0\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build preprocess pipeline\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "max_words = 200\n",
    "vocab_size = len(tencent_w2v)\n",
    "\n",
    "preprocess_pipeline = make_pipeline(\n",
    "    FunctionTransformer(preprocess_texts, validate=False)\n",
    "    , Text2SeqTransformer(num_words=MAX_NUM_WORDS)\n",
    "    , PaddingTransformer(maxlen=max_words)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 475 ms, total: 34.7 s\n",
      "Wall time: 37.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('functiontransformer',\n",
       "                 FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "                                     func=<function preprocess_texts at 0x7f9f2ce2d0d0>,\n",
       "                                     inv_kw_args=None, inverse_func=None,\n",
       "                                     kw_args=None, pass_y='deprecated',\n",
       "                                     validate=False)),\n",
       "                ('text2seqtransformer', Text2SeqTransformer()),\n",
       "                ('paddingtransformer', PaddingTransformer(maxlen=200))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "preprocess_pipeline.fit(list(train_df['q1']) + list(train_df['q2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 61486, 200)\n"
     ]
    }
   ],
   "source": [
    "x_left = preprocess_pipeline.transform(train_df['q1'])\n",
    "x_right = preprocess_pipeline.transform(train_df['q2'])\n",
    "# this will be the input of the siamese network\n",
    "x_pairs = [x_left, x_right]   \n",
    "\n",
    "y_pairs = train_df['label'].values\n",
    "print(np.shape(x_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Lambda, Subtract, Conv1D, MaxPooling1D, Flatten, Embedding, LSTM, Bidirectional\n",
    "from keras.layers import BatchNormalization, concatenate\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10278\n"
     ]
    }
   ],
   "source": [
    "# get word dict\n",
    "tokenize_texts = preprocess_texts(list(train_df['q1']) + list(train_df['q2']))\n",
    "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer.fit_on_texts(tokenize_texts)\n",
    "word_index = tokenizer.word_index\n",
    "print(len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'花呗': 1,\n",
       " '我': 2,\n",
       " '的': 3,\n",
       " '，': 4,\n",
       " '了': 5,\n",
       " '吗': 6,\n",
       " '借呗': 7,\n",
       " '怎么': 8,\n",
       " '还': 9,\n",
       " '可以': 10,\n",
       " '还款': 11,\n",
       " '为什么': 12,\n",
       " '额度': 13,\n",
       " '蚂蚁借呗': 14,\n",
       " '是': 15,\n",
       " '分期': 16,\n",
       " '开通': 17,\n",
       " '用花呗': 18,\n",
       " '钱': 19,\n",
       " '用': 20,\n",
       " '没有': 21,\n",
       " '有': 22,\n",
       " '什么': 23,\n",
       " '不能': 24,\n",
       " '不': 25,\n",
       " '在': 26,\n",
       " '能': 27,\n",
       " '支付宝': 28,\n",
       " '付款': 29,\n",
       " '月': 30,\n",
       " '支付': 31,\n",
       " '蚂蚁花呗': 32,\n",
       " '多少': 33,\n",
       " '使用': 34,\n",
       " '显示': 35,\n",
       " '没': 36,\n",
       " '现在': 37,\n",
       " '提前': 38,\n",
       " '到': 39,\n",
       " '会': 40,\n",
       " '退款': 41,\n",
       " '银行卡': 42,\n",
       " '时候': 43,\n",
       " '后': 44,\n",
       " '不了': 45,\n",
       " '申请': 46,\n",
       " '关闭': 47,\n",
       " '要': 48,\n",
       " '这个': 49,\n",
       " '和': 50,\n",
       " '借': 51,\n",
       " '如何': 52,\n",
       " '已经': 53,\n",
       " '怎么办': 54,\n",
       " '么': 55,\n",
       " '收款': 56,\n",
       " '都': 57,\n",
       " '使': 58,\n",
       " '账单': 59,\n",
       " '买': 60,\n",
       " '淘宝': 61,\n",
       " '影响': 62,\n",
       " '想': 63,\n",
       " '上': 64,\n",
       " '账号': 65,\n",
       " '还清': 66,\n",
       " '就': 67,\n",
       " '还了': 68,\n",
       " '临时': 69,\n",
       " '还是': 70,\n",
       " '号': 71,\n",
       " '里': 72,\n",
       " '利息': 73,\n",
       " '自动': 74,\n",
       " '逾期': 75,\n",
       " '绑定': 76,\n",
       " '信用卡': 77,\n",
       " '支持': 78,\n",
       " '把': 79,\n",
       " '手续费': 80,\n",
       " '余额宝': 81,\n",
       " '但是': 82,\n",
       " '取消': 83,\n",
       " '给': 84,\n",
       " '用不了': 85,\n",
       " '扣款': 86,\n",
       " '商家': 87,\n",
       " '扣': 88,\n",
       " '一个': 89,\n",
       " '退': 90,\n",
       " '花呗逾期': 91,\n",
       " '东西': 92,\n",
       " '恢复': 93,\n",
       " '需要': 94,\n",
       " '个': 95,\n",
       " '余额': 96,\n",
       " '手机': 97,\n",
       " '是不是': 98,\n",
       " '怎样': 99,\n",
       " '还款日': 100,\n",
       " '账户': 101,\n",
       " '网商贷': 102,\n",
       " '也': 103,\n",
       " '手机号': 104,\n",
       " '哪里': 105,\n",
       " '消费': 106,\n",
       " '才能': 107,\n",
       " '冻结': 108,\n",
       " '还有': 109,\n",
       " '完': 110,\n",
       " '多久': 111,\n",
       " '。': 112,\n",
       " '金额': 113,\n",
       " '只能': 114,\n",
       " '分': 115,\n",
       " '之前': 116,\n",
       " '提升': 117,\n",
       " '借款': 118,\n",
       " '到账': 119,\n",
       " '里面': 120,\n",
       " '不是': 121,\n",
       " '款': 122,\n",
       " '信用': 123,\n",
       " '已': 124,\n",
       " '今天': 125,\n",
       " '换': 126,\n",
       " '一次': 127,\n",
       " '说': 128,\n",
       " '自动还款': 129,\n",
       " '？': 130,\n",
       " '嘛': 131,\n",
       " '能不能': 132,\n",
       " '才': 133,\n",
       " '设置': 134,\n",
       " '不可以': 135,\n",
       " '再': 136,\n",
       " '被': 137,\n",
       " '另一个': 138,\n",
       " '收钱码': 139,\n",
       " '不用': 140,\n",
       " '成功': 141,\n",
       " '如果': 142,\n",
       " '最低还款': 143,\n",
       " '期': 144,\n",
       " '分期付款': 145,\n",
       " '意思': 146,\n",
       " '还要': 147,\n",
       " '以前': 148,\n",
       " '记录': 149,\n",
       " '帮': 150,\n",
       " '元': 151,\n",
       " '付': 152,\n",
       " '提示': 153,\n",
       " '无法': 154,\n",
       " '话费': 155,\n",
       " '从': 156,\n",
       " '一天': 157,\n",
       " '多': 158,\n",
       " '时间': 159,\n",
       " '提额': 160,\n",
       " '怎么回事': 161,\n",
       " '又': 162,\n",
       " '去': 163,\n",
       " '未': 164,\n",
       " '为啥': 165,\n",
       " '下个月': 166,\n",
       " '能用': 167,\n",
       " '身份证': 168,\n",
       " '号码': 169,\n",
       " '下': 170,\n",
       " '之后': 171,\n",
       " '日期': 172,\n",
       " '看': 173,\n",
       " '呀': 174,\n",
       " '对': 175,\n",
       " '开': 176,\n",
       " '吧': 177,\n",
       " '让': 178,\n",
       " '充值': 179,\n",
       " '通过': 180,\n",
       " '退回': 181,\n",
       " '以后': 182,\n",
       " '积分': 183,\n",
       " '怎么样': 184,\n",
       " '一直': 185,\n",
       " '电费': 186,\n",
       " '哪': 187,\n",
       " '那': 188,\n",
       " '一样': 189,\n",
       " '交': 190,\n",
       " '借呗逾期': 191,\n",
       " '每个': 192,\n",
       " '到期': 193,\n",
       " '一个月': 194,\n",
       " '借钱': 195,\n",
       " '每月': 196,\n",
       " '过': 197,\n",
       " '只有': 198,\n",
       " '但': 199,\n",
       " '条件': 200,\n",
       " '这': 201,\n",
       " '就是': 202,\n",
       " '押金': 203,\n",
       " '找不到': 204,\n",
       " '红包': 205,\n",
       " '我要': 206,\n",
       " '收': 207,\n",
       " '可': 208,\n",
       " '购物': 209,\n",
       " '然后': 210,\n",
       " '是否': 211,\n",
       " '限制': 212,\n",
       " '查询': 213,\n",
       " '你': 214,\n",
       " '二维码': 215,\n",
       " '两个': 216,\n",
       " '自己': 217,\n",
       " '蚂蚁': 218,\n",
       " '收款码': 219,\n",
       " '可是': 220,\n",
       " '密码': 221,\n",
       " '限额': 222,\n",
       " '一下': 223,\n",
       " '手机号码': 224,\n",
       " '短信': 225,\n",
       " '知道': 226,\n",
       " '会不会': 227,\n",
       " '收钱': 228,\n",
       " '为': 229,\n",
       " '改': 230,\n",
       " '跟': 231,\n",
       " '扣钱': 232,\n",
       " '授权': 233,\n",
       " '交易': 234,\n",
       " '别人': 235,\n",
       " '怎么算': 236,\n",
       " '一次性': 237,\n",
       " '降低': 238,\n",
       " '商品': 239,\n",
       " '我用': 240,\n",
       " '点': 241,\n",
       " '登录': 242,\n",
       " '查看': 243,\n",
       " '提现': 244,\n",
       " '重新': 245,\n",
       " '提醒': 246,\n",
       " '不够': 247,\n",
       " '更改': 248,\n",
       " '修改': 249,\n",
       " '时': 250,\n",
       " '结清': 251,\n",
       " '免息': 252,\n",
       " '几号': 253,\n",
       " '信息': 254,\n",
       " '系统': 255,\n",
       " '最低': 256,\n",
       " '怎么还款': 257,\n",
       " '删除': 258,\n",
       " '转': 259,\n",
       " '为何': 260,\n",
       " '功能': 261,\n",
       " '充': 262,\n",
       " '过期': 263,\n",
       " '提高': 264,\n",
       " '直接': 265,\n",
       " '算': 266,\n",
       " '芝麻信用': 267,\n",
       " '验证码': 268,\n",
       " '有没有': 269,\n",
       " '主动': 270,\n",
       " '几天': 271,\n",
       " '费用': 272,\n",
       " '不想': 273,\n",
       " '可不可以': 274,\n",
       " '收到': 275,\n",
       " '订单': 276,\n",
       " '朋友': 277,\n",
       " '提': 278,\n",
       " '方式': 279,\n",
       " '购买': 280,\n",
       " '全部': 281,\n",
       " '贷款': 282,\n",
       " '与': 283,\n",
       " '确认': 284,\n",
       " '选择': 285,\n",
       " '花': 286,\n",
       " '银行': 287,\n",
       " '那么': 288,\n",
       " '评估': 289,\n",
       " '当天': 290,\n",
       " '卡': 291,\n",
       " '可用': 292,\n",
       " '退货': 293,\n",
       " '！': 294,\n",
       " '收货': 295,\n",
       " '看到': 296,\n",
       " '来': 297,\n",
       " '得': 298,\n",
       " '更换': 299,\n",
       " '查': 300,\n",
       " '兑换': 301,\n",
       " '安全': 302,\n",
       " '最多': 303,\n",
       " '却': 304,\n",
       " '呗': 305,\n",
       " '操作': 306,\n",
       " '刚刚': 307,\n",
       " '刷脸': 308,\n",
       " '上面': 309,\n",
       " '网商': 310,\n",
       " '验证': 311,\n",
       " '注销': 312,\n",
       " '关': 313,\n",
       " '另外': 314,\n",
       " '中': 315,\n",
       " '火车票': 316,\n",
       " '最高': 317,\n",
       " '还款额': 318,\n",
       " '新': 319,\n",
       " '风险': 320,\n",
       " '审核': 321,\n",
       " '欠款': 322,\n",
       " '扫码': 323,\n",
       " '扣除': 324,\n",
       " '天': 325,\n",
       " '忘记': 326,\n",
       " '昨天': 327,\n",
       " '调整': 328,\n",
       " '咋': 329,\n",
       " '有钱': 330,\n",
       " '日': 331,\n",
       " '只': 332,\n",
       " '继续': 333,\n",
       " '失败': 334,\n",
       " '扫': 335,\n",
       " '线下': 336,\n",
       " '原因': 337,\n",
       " '欠': 338,\n",
       " '帐号': 339,\n",
       " '上个月': 340,\n",
       " '期限': 341,\n",
       " '几个': 342,\n",
       " '认证': 343,\n",
       " '问': 344,\n",
       " '符合': 345,\n",
       " '微信': 346,\n",
       " '放款': 347,\n",
       " '产生': 348,\n",
       " '存在': 349,\n",
       " '好': 350,\n",
       " '卖家': 351,\n",
       " '再次': 352,\n",
       " '刚才': 353,\n",
       " '这么': 354,\n",
       " '负': 355,\n",
       " '先': 356,\n",
       " '进去': 357,\n",
       " '超市': 358,\n",
       " '返现': 359,\n",
       " '变成': 360,\n",
       " '他': 361,\n",
       " '的话': 362,\n",
       " '情况': 363,\n",
       " '美团': 364,\n",
       " '问题': 365,\n",
       " '不到': 366,\n",
       " '打开': 367,\n",
       " '一笔': 368,\n",
       " '活动': 369,\n",
       " '六个月': 370,\n",
       " '变': 371,\n",
       " '度': 372,\n",
       " '收不到': 373,\n",
       " '双十一': 374,\n",
       " '还会': 375,\n",
       " '开花': 376,\n",
       " '晚': 377,\n",
       " '页面': 378,\n",
       " '滴滴': 379,\n",
       " '解除': 380,\n",
       " '店铺': 381,\n",
       " '高': 382,\n",
       " '当月': 383,\n",
       " '请': 384,\n",
       " '不会': 385,\n",
       " '不行': 386,\n",
       " '单车': 387,\n",
       " '一期': 388,\n",
       " '电脑': 389,\n",
       " '出来': 390,\n",
       " '透支': 391,\n",
       " '开不了': 392,\n",
       " '邀请': 393,\n",
       " '最后': 394,\n",
       " '不足': 395,\n",
       " '啦': 396,\n",
       " '切换': 397,\n",
       " '其他': 398,\n",
       " '没用': 399,\n",
       " '怎么弄': 400,\n",
       " '一年': 401,\n",
       " '出现': 402,\n",
       " '一起': 403,\n",
       " '做': 404,\n",
       " '超过': 405,\n",
       " '绑': 406,\n",
       " '按': 407,\n",
       " '不要': 408,\n",
       " '本月': 409,\n",
       " '不见': 410,\n",
       " '该': 411,\n",
       " '通知': 412,\n",
       " '关掉': 413,\n",
       " '代付': 414,\n",
       " '哪些': 415,\n",
       " '必须': 416,\n",
       " '原来': 417,\n",
       " '密付': 418,\n",
       " '证明': 419,\n",
       " '正常': 420,\n",
       " '人脸识别': 421,\n",
       " '推迟': 422,\n",
       " '领取': 423,\n",
       " '少': 424,\n",
       " '双': 425,\n",
       " '你们': 426,\n",
       " '一': 427,\n",
       " '两次': 428,\n",
       " '找': 429,\n",
       " '缴费': 430,\n",
       " '繁忙': 431,\n",
       " '服务费': 432,\n",
       " '升级': 433,\n",
       " '几次': 434,\n",
       " '用完': 435,\n",
       " '能否': 436,\n",
       " '出账': 437,\n",
       " '服务': 438,\n",
       " '口碑': 439,\n",
       " '天猫': 440,\n",
       " '多长时间': 441,\n",
       " '低': 442,\n",
       " '负面': 443,\n",
       " '抽奖': 444,\n",
       " '几点': 445,\n",
       " '总额': 446,\n",
       " '因为': 447,\n",
       " '按时': 448,\n",
       " '别的': 449,\n",
       " '满足': 450,\n",
       " '津贴': 451,\n",
       " '客户': 452,\n",
       " '扣费': 453,\n",
       " '刚': 454,\n",
       " '区别': 455,\n",
       " '关系': 456,\n",
       " '收费': 457,\n",
       " '前': 458,\n",
       " '明细': 459,\n",
       " '没到': 460,\n",
       " '没收': 461,\n",
       " '负数': 462,\n",
       " '芝麻分': 463,\n",
       " '次': 464,\n",
       " '注册': 465,\n",
       " '解冻': 466,\n",
       " '免息券': 467,\n",
       " '好友': 468,\n",
       " '您': 469,\n",
       " '突然': 470,\n",
       " '人': 471,\n",
       " '停用': 472,\n",
       " '通讯录': 473,\n",
       " '延期': 474,\n",
       " '出': 475,\n",
       " '开始': 476,\n",
       " '信用分': 477,\n",
       " '掉': 478,\n",
       " '开启': 479,\n",
       " '登陆': 480,\n",
       " '明天': 481,\n",
       " '小心': 482,\n",
       " '商户': 483,\n",
       " '几期': 484,\n",
       " '月份': 485,\n",
       " '那里': 486,\n",
       " '、': 487,\n",
       " '买家': 488,\n",
       " '同时': 489,\n",
       " '手动': 490,\n",
       " '收取': 491,\n",
       " '计算': 492,\n",
       " '信誉': 493,\n",
       " '所有': 494,\n",
       " '刷': 495,\n",
       " '叫': 496,\n",
       " '将': 497,\n",
       " '学历': 498,\n",
       " '忘': 499,\n",
       " '应该': 500,\n",
       " '预期': 501,\n",
       " '尽情': 502,\n",
       " '更新': 503,\n",
       " '打车': 504,\n",
       " '实体店': 505,\n",
       " '买手机': 506,\n",
       " '衣服': 507,\n",
       " '一部分': 508,\n",
       " '剩下': 509,\n",
       " '应': 510,\n",
       " '全额': 511,\n",
       " '帐': 512,\n",
       " '处理': 513,\n",
       " '店': 514,\n",
       " '办法': 515,\n",
       " '帐单': 516,\n",
       " '境外': 517,\n",
       " '两天': 518,\n",
       " '领': 519,\n",
       " '重复': 520,\n",
       " '转到': 521,\n",
       " '转入': 522,\n",
       " '哪个': 523,\n",
       " '外卖': 524,\n",
       " '降': 525,\n",
       " '还款期': 526,\n",
       " '每天': 527,\n",
       " '码': 528,\n",
       " '实名': 529,\n",
       " '暂时': 530,\n",
       " '九号': 531,\n",
       " '每次': 532,\n",
       " '以': 533,\n",
       " '第一次': 534,\n",
       " '卡里': 535,\n",
       " '延迟': 536,\n",
       " '解绑': 537,\n",
       " '用于': 538,\n",
       " '一般': 539,\n",
       " '一半': 540,\n",
       " '不可': 541,\n",
       " '停': 542,\n",
       " '机票': 543,\n",
       " '想要': 544,\n",
       " '比': 545,\n",
       " '三个': 546,\n",
       " '个人': 547,\n",
       " '打不开': 548,\n",
       " '找到': 549,\n",
       " '顾客': 550,\n",
       " '剩余': 551,\n",
       " '啥': 552,\n",
       " '马上': 553,\n",
       " '电话': 554,\n",
       " '怎样才能': 555,\n",
       " '换成': 556,\n",
       " '明明': 557,\n",
       " '部分': 558,\n",
       " '转账': 559,\n",
       " '上传': 560,\n",
       " '本金': 561,\n",
       " '会员': 562,\n",
       " '退回来': 563,\n",
       " '向': 564,\n",
       " '它': 565,\n",
       " '客服': 566,\n",
       " '利率': 567,\n",
       " '商贷': 568,\n",
       " '营业执照': 569,\n",
       " '这样': 570,\n",
       " '块钱': 571,\n",
       " '流量': 572,\n",
       " '总是': 573,\n",
       " '共享单车': 574,\n",
       " '这笔': 575,\n",
       " '完善': 576,\n",
       " '看看': 577,\n",
       " '关联': 578,\n",
       " '入口': 579,\n",
       " '万': 580,\n",
       " '永久': 581,\n",
       " '成': 582,\n",
       " '老是': 583,\n",
       " '邮政储蓄': 584,\n",
       " '或者': 585,\n",
       " '办': 586,\n",
       " '涨': 587,\n",
       " '信用度': 588,\n",
       " '最长': 589,\n",
       " '要求': 590,\n",
       " '看不到': 591,\n",
       " '我刚': 592,\n",
       " '是从': 593,\n",
       " '或': 594,\n",
       " '不让': 595,\n",
       " '零时': 596,\n",
       " '很': 597,\n",
       " '额': 598,\n",
       " '退出': 599,\n",
       " '付钱': 600,\n",
       " '改成': 601,\n",
       " '块': 602,\n",
       " '体验': 603,\n",
       " '当前': 604,\n",
       " '资料': 605,\n",
       " '收不了': 606,\n",
       " '酒店': 607,\n",
       " '游戏': 608,\n",
       " '进行': 609,\n",
       " '本人': 610,\n",
       " '啥时候': 611,\n",
       " '最晚': 612,\n",
       " '对方': 613,\n",
       " '我换': 614,\n",
       " '同一个': 615,\n",
       " '邮箱': 616,\n",
       " '调': 617,\n",
       " '总': 618,\n",
       " '能分': 619,\n",
       " '不同': 620,\n",
       " '点击': 621,\n",
       " '固定': 622,\n",
       " '后能': 623,\n",
       " '全款': 624,\n",
       " '输入': 625,\n",
       " '当面': 626,\n",
       " '我查': 627,\n",
       " '送': 628,\n",
       " '我能': 629,\n",
       " '回来': 630,\n",
       " '完款': 631,\n",
       " '网上': 632,\n",
       " '丢': 633,\n",
       " '账': 634,\n",
       " '加油': 635,\n",
       " '选项': 636,\n",
       " '拿': 637,\n",
       " '卷': 638,\n",
       " '免费': 639,\n",
       " '代扣': 640,\n",
       " '现金': 641,\n",
       " '冲': 642,\n",
       " '暂': 643,\n",
       " '生活': 644,\n",
       " '这边': 645,\n",
       " '小': 646,\n",
       " '够': 647,\n",
       " '消除': 648,\n",
       " '权限': 649,\n",
       " '产品': 650,\n",
       " '小时': 651,\n",
       " '签约': 652,\n",
       " '回': 653,\n",
       " '一万': 654,\n",
       " '公积金': 655,\n",
       " '三期': 656,\n",
       " '身份': 657,\n",
       " '打': 658,\n",
       " '运费': 659,\n",
       " '费': 660,\n",
       " '优惠券': 661,\n",
       " '六期': 662,\n",
       " '首选': 663,\n",
       " '抽': 664,\n",
       " '一共': 665,\n",
       " '我们': 666,\n",
       " '花贝': 667,\n",
       " '有个': 668,\n",
       " '而且': 669,\n",
       " '减少': 670,\n",
       " '一点': 671,\n",
       " '会扣': 672,\n",
       " '一定': 673,\n",
       " '履约': 674,\n",
       " '顺序': 675,\n",
       " '次数': 676,\n",
       " '调低': 677,\n",
       " '退还': 678,\n",
       " '用来': 679,\n",
       " '弄': 680,\n",
       " '等': 681,\n",
       " '迟': 682,\n",
       " '免': 683,\n",
       " '所以': 684,\n",
       " '资格': 685,\n",
       " '水电费': 686,\n",
       " '不好': 687,\n",
       " '而': 688,\n",
       " '那些': 689,\n",
       " '先息': 690,\n",
       " '用户': 691,\n",
       " '除了': 692,\n",
       " '上次': 693,\n",
       " '达到': 694,\n",
       " '后面': 695,\n",
       " '咋办': 696,\n",
       " '麻烦': 697,\n",
       " '并': 698,\n",
       " '帐户': 699,\n",
       " '要是': 700,\n",
       " '没法': 701,\n",
       " '好久': 702,\n",
       " '发': 703,\n",
       " '怎': 704,\n",
       " '优惠': 705,\n",
       " '选': 706,\n",
       " '优先': 707,\n",
       " '帮忙': 708,\n",
       " '地方': 709,\n",
       " '经常': 710,\n",
       " '借出来': 711,\n",
       " '交了': 712,\n",
       " '晚上': 713,\n",
       " '预留': 714,\n",
       " '哪儿': 715,\n",
       " '一张': 716,\n",
       " '最迟': 717,\n",
       " '人工': 718,\n",
       " '办理': 719,\n",
       " '错': 720,\n",
       " '咨询': 721,\n",
       " '第一期': 722,\n",
       " '消失': 723,\n",
       " '退票': 724,\n",
       " '后来': 725,\n",
       " '这是': 726,\n",
       " '免单': 727,\n",
       " '最近': 728,\n",
       " '延长': 729,\n",
       " '这里': 730,\n",
       " '苹果': 731,\n",
       " '快': 732,\n",
       " '商店': 733,\n",
       " '界面': 734,\n",
       " '可能': 735,\n",
       " '谢谢': 736,\n",
       " '老': 737,\n",
       " '增加': 738,\n",
       " '久': 739,\n",
       " '升': 740,\n",
       " '进不去': 741,\n",
       " '款项': 742,\n",
       " '无': 743,\n",
       " '资金': 744,\n",
       " '摩拜': 745,\n",
       " '货': 746,\n",
       " '干嘛': 747,\n",
       " '确定': 748,\n",
       " '提交': 749,\n",
       " '长': 750,\n",
       " '单笔': 751,\n",
       " '钱会': 752,\n",
       " '填': 753,\n",
       " '尾款': 754,\n",
       " '转移': 755,\n",
       " '用过': 756,\n",
       " '券': 757,\n",
       " '登': 758,\n",
       " '算不算': 759,\n",
       " '盒子': 760,\n",
       " '超出': 761,\n",
       " '租': 762,\n",
       " '满': 763,\n",
       " '当时': 764,\n",
       " '一致': 765,\n",
       " '房贷': 766,\n",
       " '按期还款': 767,\n",
       " 'app': 768,\n",
       " '好处': 769,\n",
       " '一号': 770,\n",
       " '差': 771,\n",
       " 'a': 772,\n",
       " '一分钱': 773,\n",
       " '缴': 774,\n",
       " '还给': 775,\n",
       " '进入': 776,\n",
       " '第一个': 777,\n",
       " '完成': 778,\n",
       " '上去': 779,\n",
       " '搞': 780,\n",
       " '导致': 781,\n",
       " '识别': 782,\n",
       " '十二': 783,\n",
       " '退到': 784,\n",
       " '芝麻': 785,\n",
       " '年': 786,\n",
       " '一千': 787,\n",
       " '这么久': 788,\n",
       " '能够': 789,\n",
       " '降额': 790,\n",
       " '关了': 791,\n",
       " '实际': 792,\n",
       " '险': 793,\n",
       " '充错': 794,\n",
       " '短期': 795,\n",
       " '储蓄卡': 796,\n",
       " '着': 797,\n",
       " '回事': 798,\n",
       " '共享': 799,\n",
       " '车票': 800,\n",
       " '花唄': 801,\n",
       " '这次': 802,\n",
       " '代': 803,\n",
       " '内': 804,\n",
       " '隐藏': 805,\n",
       " '礼包': 806,\n",
       " '解决': 807,\n",
       " '本': 808,\n",
       " '奖励金': 809,\n",
       " '贷': 810,\n",
       " '笔': 811,\n",
       " '半年': 812,\n",
       " '再用': 813,\n",
       " '三天': 814,\n",
       " '联系': 815,\n",
       " '行': 816,\n",
       " '能收': 817,\n",
       " '具体': 818,\n",
       " '抵扣': 819,\n",
       " '只要': 820,\n",
       " '我点': 821,\n",
       " '我关': 822,\n",
       " '日利率': 823,\n",
       " '比如': 824,\n",
       " '本来': 825,\n",
       " '中午': 826,\n",
       " '回复': 827,\n",
       " '不符': 828,\n",
       " '随时': 829,\n",
       " '饿': 830,\n",
       " '多钱': 831,\n",
       " '找回': 832,\n",
       " '其它': 833,\n",
       " '查不到': 834,\n",
       " '什么样': 835,\n",
       " '填写': 836,\n",
       " '十二个': 837,\n",
       " '全': 838,\n",
       " '谁': 839,\n",
       " '门店': 840,\n",
       " '符合条件': 841,\n",
       " '添加': 842,\n",
       " '邮政': 843,\n",
       " '没用过': 844,\n",
       " '好像': 845,\n",
       " '可否': 846,\n",
       " '服务商': 847,\n",
       " '加': 848,\n",
       " '不变': 849,\n",
       " '结果': 850,\n",
       " '需': 851,\n",
       " '撤销': 852,\n",
       " 'q币': 853,\n",
       " '周期': 854,\n",
       " '一月': 855,\n",
       " '只是': 856,\n",
       " '大': 857,\n",
       " '微贷': 858,\n",
       " '下降': 859,\n",
       " '访问': 860,\n",
       " '真的': 861,\n",
       " '单': 862,\n",
       " '大于': 863,\n",
       " '花费': 864,\n",
       " '麽': 865,\n",
       " '太': 866,\n",
       " '十号': 867,\n",
       " '减': 868,\n",
       " '改变': 869,\n",
       " '缴纳': 870,\n",
       " '进': 871,\n",
       " '就要': 872,\n",
       " '激活': 873,\n",
       " '合并': 874,\n",
       " '旧': 875,\n",
       " '住': 876,\n",
       " '人脸': 877,\n",
       " '大额': 878,\n",
       " '啥意思': 879,\n",
       " '大概': 880,\n",
       " '发短信': 881,\n",
       " '消息': 882,\n",
       " '昨晚': 883,\n",
       " '最少': 884,\n",
       " '名下': 885,\n",
       " '…': 886,\n",
       " '封': 887,\n",
       " '提到': 888,\n",
       " '剩': 889,\n",
       " '中断': 890,\n",
       " '放在': 891,\n",
       " '上限': 892,\n",
       " '其中': 893,\n",
       " '改为': 894,\n",
       " '店家': 895,\n",
       " '最大': 896,\n",
       " '软件': 897,\n",
       " '点错': 898,\n",
       " '返回': 899,\n",
       " '及时': 900,\n",
       " 'b': 901,\n",
       " '人家': 902,\n",
       " '立即': 903,\n",
       " '客人': 904,\n",
       " '京东': 905,\n",
       " '翻倍': 906,\n",
       " '解': 907,\n",
       " '获得': 908,\n",
       " '有些': 909,\n",
       " '那天': 910,\n",
       " '何时': 911,\n",
       " '延后': 912,\n",
       " '银行贷款': 913,\n",
       " '了解': 914,\n",
       " '月底': 915,\n",
       " '机会': 916,\n",
       " '换款': 917,\n",
       " '清除': 918,\n",
       " '付清': 919,\n",
       " '默认': 920,\n",
       " '总共': 921,\n",
       " '过后': 922,\n",
       " '有效期': 923,\n",
       " '变化': 924,\n",
       " '事': 925,\n",
       " '花呗pass': 926,\n",
       " '端': 927,\n",
       " '为什': 928,\n",
       " '期间': 929,\n",
       " '换个': 930,\n",
       " '进度': 931,\n",
       " '第二次': 932,\n",
       " '电话号码': 933,\n",
       " '业务': 934,\n",
       " '超额': 935,\n",
       " '有关': 936,\n",
       " '要收': 937,\n",
       " '规定': 938,\n",
       " '暂停': 939,\n",
       " '两笔': 940,\n",
       " '卡上': 941,\n",
       " '己': 942,\n",
       " '还收': 943,\n",
       " '删掉': 944,\n",
       " '一件': 945,\n",
       " '违约': 946,\n",
       " '还用': 947,\n",
       " '摇': 948,\n",
       " '写': 949,\n",
       " '花钱': 950,\n",
       " '加油站': 951,\n",
       " '返': 952,\n",
       " '他人': 953,\n",
       " '不起': 954,\n",
       " '黄车': 955,\n",
       " '物品': 956,\n",
       " '被封': 957,\n",
       " '很多': 958,\n",
       " '到底': 959,\n",
       " '投诉': 960,\n",
       " '解开': 961,\n",
       " '价格': 962,\n",
       " '综合': 963,\n",
       " '应用': 964,\n",
       " '劵': 965,\n",
       " '转换': 966,\n",
       " '哪里找': 967,\n",
       " '没钱': 968,\n",
       " '常用': 969,\n",
       " '能换': 970,\n",
       " '不算': 971,\n",
       " '同一': 972,\n",
       " '不成': 973,\n",
       " '没扣': 974,\n",
       " '查查': 975,\n",
       " '订': 976,\n",
       " '用途': 977,\n",
       " '任何': 978,\n",
       " '问问': 979,\n",
       " '长时间': 980,\n",
       " '每期': 981,\n",
       " '包括': 982,\n",
       " '能查': 983,\n",
       " '当日': 984,\n",
       " 'qq': 985,\n",
       " '双十二': 986,\n",
       " '上用': 987,\n",
       " '后本': 988,\n",
       " '快速': 989,\n",
       " '哪天': 990,\n",
       " '欠钱': 991,\n",
       " '允许': 992,\n",
       " '走': 993,\n",
       " '另': 994,\n",
       " '到时候': 995,\n",
       " '最': 996,\n",
       " '企业': 997,\n",
       " '免密': 998,\n",
       " '宝': 999,\n",
       " '下载': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(w2v):\n",
    "    num_words = min(MAX_NUM_WORDS, len(w2v) + 1) if MAX_NUM_WORDS else len(w2v) + 1\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= MAX_NUM_WORDS:\n",
    "            continue\n",
    "        embedding_vector = w2v.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def get_embeddings_loop():\n",
    "    num_words = min(MAX_NUM_WORDS, len(w2v) + 1) if MAX_NUM_WORDS else len(w2v) + 1\n",
    "    embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = w2v.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def get_keras_embeddings_layers(w2v, maxlen):\n",
    "    from keras.layers import Embedding\n",
    "    embeddings = get_embeddings(w2v)\n",
    "    x_embedded = Embedding(\n",
    "        embeddings.shape[0]\n",
    "        , embeddings.shape[1]\n",
    "        , input_length=maxlen\n",
    "        , trainable=False\n",
    "        , weights=[embeddings]\n",
    "    )\n",
    "    return x_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_neg_manhattan_distance(difference):\n",
    "    \"\"\" Compute the exponent of the opposite of the L1 norm of a vector, to get the left/right inputs\n",
    "    similarity from the inputs differences. This function is used to turned the unbounded\n",
    "    L1 distance to a similarity measure between 0 and 1\"\"\"\n",
    "    return K.exp(-K.sum(K.abs(difference), axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_lstm(max_length, embedding_layer):\n",
    "    \"\"\" Define, compile and return a siamese LSTM model \"\"\"\n",
    "    input_shape = (max_length,)\n",
    "    left_input = Input(input_shape, name='left_input')\n",
    "    right_input = Input(input_shape, name='right_input')\n",
    "\n",
    "    # Define a single sequential model for both arms.\n",
    "    # In this example I've chosen a simple bidirectional LSTM with no dropout\n",
    "    seq = Sequential(name='sequential_network')\n",
    "    seq.add(embedding_layer)\n",
    "    seq.add(Bidirectional(LSTM(32, dropout=0., recurrent_dropout=0.)))\n",
    "    \n",
    "    left_output = seq(left_input)\n",
    "    right_output = seq(right_input)\n",
    "\n",
    "    # Here we subtract the neuron values of the last layer from the left arm \n",
    "    # with the corresponding values from the right arm\n",
    "    subtracted = Subtract(name='pair_representations_difference')([left_output, right_output])\n",
    "    \n",
    "    # 1 This is exponent negative manhattan distance\n",
    "    \n",
    "    manhattan_lstm_distance = Lambda(exponent_neg_manhattan_distance, name='masltsm_distance')(subtracted)\n",
    "    \n",
    "    # 2 This is sigmoid \n",
    "    L1_layer = Lambda(lambda tensors: K.abs(tensors))\n",
    "    L1_distance = L1_layer(subtracted)\n",
    "    prediction = Dense(1, activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # 3 Use bn and dense to make the distance.\n",
    "    \n",
    "    concated = concatenate([left_output, right_output])\n",
    "    concated = BatchNormalization()(concated)\n",
    "    concated = Dropout(0.3)(concated)\n",
    "    concated = Dense(64, activation='relu')(concated)\n",
    "    concated = BatchNormalization()(concated)\n",
    "    concated = Dropout(0.3)(concated)\n",
    "    preds = Dense(1, activation='sigmoid')(concated)\n",
    "\n",
    "    \n",
    "    # siamese_net = Model(inputs=[left_input, right_input], outputs=manhattan_lstm_distance)\n",
    "    # siamese_net = Model(inputs=[left_input, right_input], outputs=prediction)\n",
    "    siamese_net = Model(inputs=[left_input, right_input], outputs=preds)\n",
    "    siamese_net.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = get_keras_embeddings_layers(tencent_w2v, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_epo_siamese_lstm = siamese_lstm(max_words, embedding_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_input (InputLayer)         (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_input (InputLayer)        (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_network (Sequential) (None, 64)           4059648     left_input[0][0]                 \n",
      "                                                                 right_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           sequential_network[1][0]         \n",
      "                                                                 sequential_network[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,068,737\n",
      "Trainable params: 68,353\n",
      "Non-trainable params: 4,000,384\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "one_epo_siamese_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55337 samples, validate on 6149 samples\n",
      "Epoch 1/2\n",
      "55337/55337 [==============================] - 551s 10ms/step - loss: 0.5188 - accuracy: 0.7870 - val_loss: 0.4301 - val_accuracy: 0.8463\n",
      "Epoch 2/2\n",
      "55337/55337 [==============================] - 550s 10ms/step - loss: 0.4686 - accuracy: 0.8122 - val_loss: 0.4069 - val_accuracy: 0.8465\n",
      "CPU times: user 40min 59s, sys: 3min 23s, total: 44min 22s\n",
      "Wall time: 18min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9f9e499dd8>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "one_epo_siamese_lstm.fit(x_pairs, y_pairs, validation_split=0.1, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30744, 200)\n"
     ]
    }
   ],
   "source": [
    "x_test_left = preprocess_pipeline.transform(test_df['q1'])\n",
    "x_test_right = preprocess_pipeline.transform(test_df['q2'])\n",
    "# this will be the input of the siamese network\n",
    "x_test_pairs = [x_test_left, x_test_right]   \n",
    "\n",
    "y_test_pairs = test_df['label'].values\n",
    "print(np.shape(x_test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run_x_test_pairs = [x_test_left[:3], x_test_right[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.23769563],\n",
       "       [0.11171392],\n",
       "       [0.13364395]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test_pairs[:3])\n",
    "one_epo_siamese_lstm.predict(dry_run_x_test_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = one_epo_siamese_lstm.evaluate(x_test_pairs, y_test_pairs, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss, accuracy:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4546530999896615, 0.8186963200569153]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"loss, accuracy:\\n\".format(score))\n",
    "[0.4546530999896615, 0.8186963200569153]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prop = one_epo_siamese_lstm.predict(x_test_pairs)\n",
    "y_pred = np.where(y_prop > 0.5, 1, 0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25162     7]\n",
      " [ 5556    19]]\n",
      "\n",
      "F1 score 0.006784502767362971\n",
      "Accuracy 0.8190541243819932\n",
      "ROC AUC SCORE 0.5015649759197333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     25169\n",
      "           1       0.73      0.00      0.01      5575\n",
      "\n",
      "    accuracy                           0.82     30744\n",
      "   macro avg       0.77      0.50      0.45     30744\n",
      "weighted avg       0.80      0.82      0.74     30744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_pairs, y_pred)  \n",
    "print(cm)  \n",
    "print()\n",
    "print(\"F1 score\", f1_score(y_test_pairs, y_pred))\n",
    "print('Accuracy', accuracy_score(y_test_pairs, y_pred))\n",
    "print('ROC AUC SCORE', roc_auc_score(y_test_pairs, y_pred))\n",
    "print(classification_report(y_test_pairs, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "manhattan_lstm_distance\n",
    "[[24975   194]\n",
    " [ 5157   418]]\n",
    "\n",
    "F1 score 0.1351220300630354\n",
    "Accuracy 0.8259497788186313\n",
    "ROC AUC SCORE 0.5336348419215253\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.99      0.90     25169\n",
    "           1       0.68      0.07      0.14      5575\n",
    "\n",
    "    accuracy                           0.83     30744\n",
    "   macro avg       0.76      0.53      0.52     30744\n",
    "weighted avg       0.80      0.83      0.76     30744\n",
    "'''\n",
    "\n",
    "'''\n",
    "bn and dense to make the distance.\n",
    "[[25162     7]\n",
    " [ 5556    19]]\n",
    "\n",
    "F1 score 0.006784502767362971\n",
    "Accuracy 0.8190541243819932\n",
    "ROC AUC SCORE 0.5015649759197333\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      1.00      0.90     25169\n",
    "           1       0.73      0.00      0.01      5575\n",
    "\n",
    "    accuracy                           0.82     30744\n",
    "   macro avg       0.77      0.50      0.45     30744\n",
    "weighted avg       0.80      0.82      0.74     30744\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
